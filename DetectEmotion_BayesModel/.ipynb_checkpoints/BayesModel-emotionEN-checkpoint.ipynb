{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "import os\n",
    "from time import time\n",
    "from pprint import pprint\n",
    "import collections\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style=\"darkgrid\")\n",
    "sns.set(font_scale=1.3)\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "np.random.seed(37)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'df_model.p'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\pickle.py\u001b[0m in \u001b[0;36mtry_read\u001b[1;34m(path, encoding)\u001b[0m\n\u001b[0;32m    165\u001b[0m                 \u001b[1;31m# We want to silencce any warnings about, e.g. moved modules.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 166\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mread_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mpkl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    167\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\pickle.py\u001b[0m in \u001b[0;36mread_wrapper\u001b[1;34m(func)\u001b[0m\n\u001b[0;32m    146\u001b[0m                             \u001b[0mcompression\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minferred_compression\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 147\u001b[1;33m                             is_text=False)\n\u001b[0m\u001b[0;32m    148\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36m_get_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text)\u001b[0m\n\u001b[0;32m    405\u001b[0m             \u001b[1;31m# Python 3 and binary mode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 406\u001b[1;33m             \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    407\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'df_model.p'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\pickle.py\u001b[0m in \u001b[0;36mtry_read\u001b[1;34m(path, encoding)\u001b[0m\n\u001b[0;32m    170\u001b[0m                 return read_wrapper(\n\u001b[1;32m--> 171\u001b[1;33m                     lambda f: pc.load(f, encoding=encoding, compat=False))\n\u001b[0m\u001b[0;32m    172\u001b[0m             \u001b[1;31m# compat pickle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\pickle.py\u001b[0m in \u001b[0;36mread_wrapper\u001b[1;34m(func)\u001b[0m\n\u001b[0;32m    146\u001b[0m                             \u001b[0mcompression\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minferred_compression\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 147\u001b[1;33m                             is_text=False)\n\u001b[0m\u001b[0;32m    148\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36m_get_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text)\u001b[0m\n\u001b[0;32m    405\u001b[0m             \u001b[1;31m# Python 3 and binary mode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 406\u001b[1;33m             \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    407\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'df_model.p'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\pickle.py\u001b[0m in \u001b[0;36mread_pickle\u001b[1;34m(path, compression)\u001b[0m\n\u001b[0;32m    176\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 177\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mtry_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    178\u001b[0m     \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\pickle.py\u001b[0m in \u001b[0;36mtry_read\u001b[1;34m(path, encoding)\u001b[0m\n\u001b[0;32m    174\u001b[0m                 return read_wrapper(\n\u001b[1;32m--> 175\u001b[1;33m                     lambda f: pc.load(f, encoding=encoding, compat=True))\n\u001b[0m\u001b[0;32m    176\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\pickle.py\u001b[0m in \u001b[0;36mread_wrapper\u001b[1;34m(func)\u001b[0m\n\u001b[0;32m    146\u001b[0m                             \u001b[0mcompression\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minferred_compression\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 147\u001b[1;33m                             is_text=False)\n\u001b[0m\u001b[0;32m    148\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36m_get_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text)\u001b[0m\n\u001b[0;32m    405\u001b[0m             \u001b[1;31m# Python 3 and binary mode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 406\u001b[1;33m             \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    407\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'df_model.p'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\pickle.py\u001b[0m in \u001b[0;36mtry_read\u001b[1;34m(path, encoding)\u001b[0m\n\u001b[0;32m    165\u001b[0m                 \u001b[1;31m# We want to silencce any warnings about, e.g. moved modules.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 166\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mread_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mpkl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    167\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\pickle.py\u001b[0m in \u001b[0;36mread_wrapper\u001b[1;34m(func)\u001b[0m\n\u001b[0;32m    146\u001b[0m                             \u001b[0mcompression\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minferred_compression\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 147\u001b[1;33m                             is_text=False)\n\u001b[0m\u001b[0;32m    148\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36m_get_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text)\u001b[0m\n\u001b[0;32m    405\u001b[0m             \u001b[1;31m# Python 3 and binary mode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 406\u001b[1;33m             \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    407\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'df_model.p'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\pickle.py\u001b[0m in \u001b[0;36mtry_read\u001b[1;34m(path, encoding)\u001b[0m\n\u001b[0;32m    170\u001b[0m                 return read_wrapper(\n\u001b[1;32m--> 171\u001b[1;33m                     lambda f: pc.load(f, encoding=encoding, compat=False))\n\u001b[0m\u001b[0;32m    172\u001b[0m             \u001b[1;31m# compat pickle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\pickle.py\u001b[0m in \u001b[0;36mread_wrapper\u001b[1;34m(func)\u001b[0m\n\u001b[0;32m    146\u001b[0m                             \u001b[0mcompression\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minferred_compression\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 147\u001b[1;33m                             is_text=False)\n\u001b[0m\u001b[0;32m    148\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36m_get_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text)\u001b[0m\n\u001b[0;32m    405\u001b[0m             \u001b[1;31m# Python 3 and binary mode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 406\u001b[1;33m             \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    407\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'df_model.p'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-30f8a5ad36ba>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_pickle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'df_model.p'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\pickle.py\u001b[0m in \u001b[0;36mread_pickle\u001b[1;34m(path, compression)\u001b[0m\n\u001b[0;32m    178\u001b[0m     \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mPY3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 180\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mtry_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'latin1'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    181\u001b[0m         \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\pickle.py\u001b[0m in \u001b[0;36mtry_read\u001b[1;34m(path, encoding)\u001b[0m\n\u001b[0;32m    173\u001b[0m             \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    174\u001b[0m                 return read_wrapper(\n\u001b[1;32m--> 175\u001b[1;33m                     lambda f: pc.load(f, encoding=encoding, compat=True))\n\u001b[0m\u001b[0;32m    176\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mtry_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\pickle.py\u001b[0m in \u001b[0;36mread_wrapper\u001b[1;34m(func)\u001b[0m\n\u001b[0;32m    145\u001b[0m         f, fh = _get_handle(path, 'rb',\n\u001b[0;32m    146\u001b[0m                             \u001b[0mcompression\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minferred_compression\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 147\u001b[1;33m                             is_text=False)\n\u001b[0m\u001b[0;32m    148\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36m_get_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text)\u001b[0m\n\u001b[0;32m    404\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    405\u001b[0m             \u001b[1;31m# Python 3 and binary mode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 406\u001b[1;33m             \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    407\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    408\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'df_model.p'"
     ]
    }
   ],
   "source": [
    "df_model = pd.read_pickle('df_model.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count_words</th>\n",
       "      <th>count_mentions</th>\n",
       "      <th>count_hashtags</th>\n",
       "      <th>count_capital_words</th>\n",
       "      <th>count_excl_quest_marks</th>\n",
       "      <th>count_urls</th>\n",
       "      <th>count_emojis</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>origin_text</th>\n",
       "      <th>likes</th>\n",
       "      <th>retweets</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>557219</th>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>neutral</td>\n",
       "      <td>5 ways Internet of things will create new  opportunities for Indian businesses!Read here http://t.co/NiroT9Xa9I #DigitalUniverseIN @emcindia</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>way internet thing creat new opportun indian busi read digitaluniversein</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5084791</th>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>neutral</td>\n",
       "      <td>As #bigdata, #cloud, and #IoT usage increases, so do #security concerns https://t.co/lXwuN7CP6s  via @ITProPortal https://t.co/8KPv2ZbcuY</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>bigdata cloud iot usag increas secur concern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4330044</th>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Hewlett Packard Enterprise Co Launches an Internet of Things Platform https://t.co/qf8qKwAhFs #iot</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>hewlett packard enterpris co launch internet thing platform iot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4846444</th>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>neutral</td>\n",
       "      <td>The Internet of Things is about to disrupt the digital economy, report says https://t.co/RFWzNYvNY1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>internet thing disrupt digit economi report say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1338071</th>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>neutral</td>\n",
       "      <td>How the #InternetOfThings is changing the World around Us http://t.co/iPz10oo7hc … #IoT</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>internetofth chang world around us iot</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         count_words  count_mentions  count_hashtags  count_capital_words  \\\n",
       "557219   20           1               1               0                     \n",
       "5084791  21           1               4               0                     \n",
       "4330044  15           0               1               0                     \n",
       "4846444  17           0               0               0                     \n",
       "1338071  14           0               2               0                     \n",
       "\n",
       "         count_excl_quest_marks  count_urls  count_emojis sentiment  \\\n",
       "557219   1                       1           0             neutral    \n",
       "5084791  0                       2           0             neutral    \n",
       "4330044  0                       1           0             neutral    \n",
       "4846444  0                       1           0             neutral    \n",
       "1338071  0                       1           0             neutral    \n",
       "\n",
       "                                                                                                                                          origin_text  \\\n",
       "557219   5 ways Internet of things will create new  opportunities for Indian businesses!Read here http://t.co/NiroT9Xa9I #DigitalUniverseIN @emcindia   \n",
       "5084791  As #bigdata, #cloud, and #IoT usage increases, so do #security concerns https://t.co/lXwuN7CP6s  via @ITProPortal https://t.co/8KPv2ZbcuY      \n",
       "4330044  Hewlett Packard Enterprise Co Launches an Internet of Things Platform https://t.co/qf8qKwAhFs #iot                                             \n",
       "4846444  The Internet of Things is about to disrupt the digital economy, report says https://t.co/RFWzNYvNY1                                            \n",
       "1338071  How the #InternetOfThings is changing the World around Us http://t.co/iPz10oo7hc … #IoT                                                        \n",
       "\n",
       "        likes  retweets  \\\n",
       "557219   0     0          \n",
       "5084791  0     0          \n",
       "4330044  1     0          \n",
       "4846444  0     1          \n",
       "1338071  0     0          \n",
       "\n",
       "                                                                       clean_text  \n",
       "557219   way internet thing creat new opportun indian busi read digitaluniversein  \n",
       "5084791  bigdata cloud iot usag increas secur concern                              \n",
       "4330044  hewlett packard enterpris co launch internet thing platform iot           \n",
       "4846444  internet thing disrupt digit economi report say                           \n",
       "1338071  internetofth chang world around us iot                                    "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_model.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_model.drop('sentiment', axis=1), df_model.sentiment, test_size=0.1, random_state=37)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColumnExtractor(TransformerMixin, BaseEstimator):\n",
    "    def __init__(self, cols):\n",
    "        self.cols = cols\n",
    "\n",
    "    def transform(self, X, **transform_params):\n",
    "        return X[self.cols]\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_vect(clf, parameters_clf, X_train, X_test, parameters_text=None, vect=None):\n",
    "    \n",
    "    textcountscols = ['count_capital_words','count_emojis','count_excl_quest_marks','count_hashtags'\n",
    "                      ,'count_mentions','count_urls','count_words']\n",
    "    \n",
    "\n",
    "    features = FeatureUnion([('textcounts', ColumnExtractor(cols=textcountscols))\n",
    "                            , ('pipe', Pipeline([('cleantext', ColumnExtractor(cols='clean_text')), ('vect', vect)]))]\n",
    "                            , n_jobs=-1)\n",
    "\n",
    "    \n",
    "    pipeline = Pipeline([\n",
    "        ('features', features)\n",
    "        , ('clf', clf)\n",
    "    ])\n",
    "    \n",
    "    # Join the parameters dictionaries together\n",
    "    parameters = dict()\n",
    "    if parameters_text:\n",
    "        parameters.update(parameters_text)\n",
    "    parameters.update(parameters_clf)\n",
    "\n",
    "    # initiate gridsearchCV with parameters and pipline\n",
    "    grid_search = GridSearchCV(pipeline, parameters, n_jobs=-1, verbose=1, cv=5)\n",
    "    \n",
    "    print(\"Performing grid search...\")\n",
    "    print(\"pipeline:\", [name for name, _ in pipeline.steps])\n",
    "    print(\"parameters:\")\n",
    "    pprint(parameters)\n",
    "\n",
    "    t0 = time()\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    print(\"done in %0.3fs\" % (time() - t0))\n",
    "    print()\n",
    "\n",
    "    print(\"Best CV score: %0.3f\" % grid_search.best_score_)\n",
    "    print(\"Best parameters set:\")\n",
    "    best_parameters = grid_search.best_estimator_.get_params()\n",
    "    for param_name in sorted(parameters.keys()):\n",
    "        print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "        \n",
    "    print(\"Test score with best_estimator_: %0.3f\" % grid_search.best_estimator_.score(X_test, y_test))\n",
    "    print(\"\\n\")\n",
    "    print(\"Classification Report Test Data\")\n",
    "    print(classification_report(y_test, grid_search.best_estimator_.predict(X_test)))\n",
    "\n",
    "    print(\"all results\")\n",
    "    means = grid_search.cv_results_['mean_test_score']\n",
    "    stds = grid_search.cv_results_['std_test_score']\n",
    "    params = grid_search.cv_results_['params']\n",
    "    for mean, stdev, param in zip(means, stds, params):\n",
    "        print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "    \n",
    "    return grid_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter grid settings for the vectorizers (Count and TFIDF)\n",
    "parameters_vect = {\n",
    "    'features__pipe__vect__max_df': (0.25, 0.5, 0.75),\n",
    "    'features__pipe__vect__ngram_range': ((1, 1), (1, 2)),\n",
    "    'features__pipe__vect__min_df': (1,2)\n",
    "}\n",
    "\n",
    "# Parameter grid settings for MultinomialNB\n",
    "parameters_mnb = {\n",
    "    'clf__alpha': (0.25, 0.5, 0.75)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "countvect = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "pipeline: ['features', 'clf']\n",
      "parameters:\n",
      "{'clf__alpha': (0.25, 0.5, 0.75),\n",
      " 'features__pipe__vect__max_df': (0.25, 0.5, 0.75),\n",
      " 'features__pipe__vect__min_df': (1, 2),\n",
      " 'features__pipe__vect__ngram_range': ((1, 1), (1, 2))}\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   27.7s\n",
      "[Parallel(n_jobs=-1)]: Done 180 out of 180 | elapsed:  1.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 119.636s\n",
      "\n",
      "Best CV score: 0.763\n",
      "Best parameters set:\n",
      "\tclf__alpha: 0.75\n",
      "\tfeatures__pipe__vect__max_df: 0.25\n",
      "\tfeatures__pipe__vect__min_df: 1\n",
      "\tfeatures__pipe__vect__ngram_range: (1, 2)\n",
      "Test score with best_estimator_: 0.774\n",
      "\n",
      "\n",
      "Classification Report Test Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.75      0.79      1333\n",
      "     neutral       0.75      0.75      0.75      1884\n",
      "    positive       0.76      0.82      0.79      1730\n",
      "\n",
      "   micro avg       0.77      0.77      0.77      4947\n",
      "   macro avg       0.78      0.77      0.78      4947\n",
      "weighted avg       0.78      0.77      0.77      4947\n",
      "\n",
      "all results\n",
      "0.709312 (0.003967) with: {'clf__alpha': 0.25, 'features__pipe__vect__max_df': 0.25, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.756210 (0.001720) with: {'clf__alpha': 0.25, 'features__pipe__vect__max_df': 0.25, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.711648 (0.004714) with: {'clf__alpha': 0.25, 'features__pipe__vect__max_df': 0.25, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.757064 (0.003586) with: {'clf__alpha': 0.25, 'features__pipe__vect__max_df': 0.25, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.716275 (0.004633) with: {'clf__alpha': 0.25, 'features__pipe__vect__max_df': 0.5, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.755290 (0.004032) with: {'clf__alpha': 0.25, 'features__pipe__vect__max_df': 0.5, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.717623 (0.004226) with: {'clf__alpha': 0.25, 'features__pipe__vect__max_df': 0.5, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.754189 (0.004421) with: {'clf__alpha': 0.25, 'features__pipe__vect__max_df': 0.5, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.716612 (0.004449) with: {'clf__alpha': 0.25, 'features__pipe__vect__max_df': 0.75, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.755447 (0.004360) with: {'clf__alpha': 0.25, 'features__pipe__vect__max_df': 0.75, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.717825 (0.003622) with: {'clf__alpha': 0.25, 'features__pipe__vect__max_df': 0.75, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.753493 (0.004202) with: {'clf__alpha': 0.25, 'features__pipe__vect__max_df': 0.75, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.715197 (0.003075) with: {'clf__alpha': 0.5, 'features__pipe__vect__max_df': 0.25, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.761915 (0.002901) with: {'clf__alpha': 0.5, 'features__pipe__vect__max_df': 0.25, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.714972 (0.003481) with: {'clf__alpha': 0.5, 'features__pipe__vect__max_df': 0.25, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.759827 (0.003770) with: {'clf__alpha': 0.5, 'features__pipe__vect__max_df': 0.25, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.720924 (0.003549) with: {'clf__alpha': 0.5, 'features__pipe__vect__max_df': 0.5, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.760613 (0.003881) with: {'clf__alpha': 0.5, 'features__pipe__vect__max_df': 0.5, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.720363 (0.003464) with: {'clf__alpha': 0.5, 'features__pipe__vect__max_df': 0.5, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.756772 (0.005158) with: {'clf__alpha': 0.5, 'features__pipe__vect__max_df': 0.5, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.721576 (0.003259) with: {'clf__alpha': 0.5, 'features__pipe__vect__max_df': 0.75, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.760545 (0.004015) with: {'clf__alpha': 0.5, 'features__pipe__vect__max_df': 0.75, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.719914 (0.003013) with: {'clf__alpha': 0.5, 'features__pipe__vect__max_df': 0.75, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.756121 (0.005467) with: {'clf__alpha': 0.5, 'features__pipe__vect__max_df': 0.75, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.717016 (0.003211) with: {'clf__alpha': 0.75, 'features__pipe__vect__max_df': 0.25, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.762904 (0.003942) with: {'clf__alpha': 0.75, 'features__pipe__vect__max_df': 0.25, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.717286 (0.003336) with: {'clf__alpha': 0.75, 'features__pipe__vect__max_df': 0.25, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.761017 (0.004033) with: {'clf__alpha': 0.75, 'features__pipe__vect__max_df': 0.25, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.723081 (0.003057) with: {'clf__alpha': 0.75, 'features__pipe__vect__max_df': 0.5, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.760231 (0.003571) with: {'clf__alpha': 0.75, 'features__pipe__vect__max_df': 0.5, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.721351 (0.003925) with: {'clf__alpha': 0.75, 'features__pipe__vect__max_df': 0.5, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.757266 (0.005861) with: {'clf__alpha': 0.75, 'features__pipe__vect__max_df': 0.5, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.723260 (0.003632) with: {'clf__alpha': 0.75, 'features__pipe__vect__max_df': 0.75, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.760006 (0.003736) with: {'clf__alpha': 0.75, 'features__pipe__vect__max_df': 0.75, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.721194 (0.002857) with: {'clf__alpha': 0.75, 'features__pipe__vect__max_df': 0.75, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.756525 (0.005341) with: {'clf__alpha': 0.75, 'features__pipe__vect__max_df': 0.75, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 2)}\n"
     ]
    }
   ],
   "source": [
    "# MultinomialNB\n",
    "best_mnb_countvect = grid_vect(mnb, parameters_mnb, X_train, X_test, parameters_text=parameters_vect, vect=countvect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidfvect = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "pipeline: ['features', 'clf']\n",
      "parameters:\n",
      "{'clf__alpha': (0.25, 0.5, 0.75),\n",
      " 'features__pipe__vect__max_df': (0.25, 0.5, 0.75),\n",
      " 'features__pipe__vect__min_df': (1, 2),\n",
      " 'features__pipe__vect__ngram_range': ((1, 1), (1, 2))}\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 180 out of 180 | elapsed:  5.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 308.657s\n",
      "\n",
      "Best CV score: 0.746\n",
      "Best parameters set:\n",
      "\tclf__alpha: 0.25\n",
      "\tfeatures__pipe__vect__max_df: 0.5\n",
      "\tfeatures__pipe__vect__min_df: 2\n",
      "\tfeatures__pipe__vect__ngram_range: (1, 2)\n",
      "Test score with best_estimator_: 0.756\n",
      "\n",
      "\n",
      "Classification Report Test Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.76      0.78      1333\n",
      "     neutral       0.73      0.72      0.73      1884\n",
      "    positive       0.75      0.79      0.77      1730\n",
      "\n",
      "   micro avg       0.76      0.76      0.76      4947\n",
      "   macro avg       0.76      0.76      0.76      4947\n",
      "weighted avg       0.76      0.76      0.76      4947\n",
      "\n",
      "all results\n",
      "0.684291 (0.004338) with: {'clf__alpha': 0.25, 'features__pipe__vect__max_df': 0.25, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.736714 (0.001216) with: {'clf__alpha': 0.25, 'features__pipe__vect__max_df': 0.25, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.687099 (0.004859) with: {'clf__alpha': 0.25, 'features__pipe__vect__max_df': 0.25, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.745362 (0.003564) with: {'clf__alpha': 0.25, 'features__pipe__vect__max_df': 0.25, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.688693 (0.005430) with: {'clf__alpha': 0.25, 'features__pipe__vect__max_df': 0.5, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.737613 (0.001650) with: {'clf__alpha': 0.25, 'features__pipe__vect__max_df': 0.5, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.691299 (0.005979) with: {'clf__alpha': 0.25, 'features__pipe__vect__max_df': 0.5, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.745564 (0.003934) with: {'clf__alpha': 0.25, 'features__pipe__vect__max_df': 0.5, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.689345 (0.005422) with: {'clf__alpha': 0.25, 'features__pipe__vect__max_df': 0.75, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.737703 (0.001411) with: {'clf__alpha': 0.25, 'features__pipe__vect__max_df': 0.75, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.691905 (0.005511) with: {'clf__alpha': 0.25, 'features__pipe__vect__max_df': 0.75, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.745384 (0.003467) with: {'clf__alpha': 0.25, 'features__pipe__vect__max_df': 0.75, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.686312 (0.004579) with: {'clf__alpha': 0.5, 'features__pipe__vect__max_df': 0.25, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.690445 (0.002669) with: {'clf__alpha': 0.5, 'features__pipe__vect__max_df': 0.25, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.689592 (0.004964) with: {'clf__alpha': 0.5, 'features__pipe__vect__max_df': 0.25, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.741813 (0.003378) with: {'clf__alpha': 0.5, 'features__pipe__vect__max_df': 0.25, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.690692 (0.005842) with: {'clf__alpha': 0.5, 'features__pipe__vect__max_df': 0.5, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.692220 (0.002340) with: {'clf__alpha': 0.5, 'features__pipe__vect__max_df': 0.5, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.693388 (0.004781) with: {'clf__alpha': 0.5, 'features__pipe__vect__max_df': 0.5, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.742464 (0.003290) with: {'clf__alpha': 0.5, 'features__pipe__vect__max_df': 0.5, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.690670 (0.005859) with: {'clf__alpha': 0.5, 'features__pipe__vect__max_df': 0.75, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.691973 (0.001947) with: {'clf__alpha': 0.5, 'features__pipe__vect__max_df': 0.75, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.693792 (0.004647) with: {'clf__alpha': 0.5, 'features__pipe__vect__max_df': 0.75, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.742083 (0.003053) with: {'clf__alpha': 0.5, 'features__pipe__vect__max_df': 0.75, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.683168 (0.004789) with: {'clf__alpha': 0.75, 'features__pipe__vect__max_df': 0.25, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.634922 (0.002260) with: {'clf__alpha': 0.75, 'features__pipe__vect__max_df': 0.25, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.690400 (0.004312) with: {'clf__alpha': 0.75, 'features__pipe__vect__max_df': 0.25, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.732492 (0.001868) with: {'clf__alpha': 0.75, 'features__pipe__vect__max_df': 0.25, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.687795 (0.004617) with: {'clf__alpha': 0.75, 'features__pipe__vect__max_df': 0.5, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.635506 (0.002561) with: {'clf__alpha': 0.75, 'features__pipe__vect__max_df': 0.5, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.694488 (0.005626) with: {'clf__alpha': 0.75, 'features__pipe__vect__max_df': 0.5, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.733952 (0.002349) with: {'clf__alpha': 0.75, 'features__pipe__vect__max_df': 0.5, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.688334 (0.004984) with: {'clf__alpha': 0.75, 'features__pipe__vect__max_df': 0.75, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.635843 (0.002182) with: {'clf__alpha': 0.75, 'features__pipe__vect__max_df': 0.75, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.694915 (0.005489) with: {'clf__alpha': 0.75, 'features__pipe__vect__max_df': 0.75, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.733682 (0.002230) with: {'clf__alpha': 0.75, 'features__pipe__vect__max_df': 0.75, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 2)}\n"
     ]
    }
   ],
   "source": [
    "best_mnb_tfidf = grid_vect(mnb, parameters_mnb, X_train, X_test, parameters_text=parameters_vect, vect=tfidfvect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#max_df: 0.25 or maximum document frequency of 25%.\n",
    "#min_df: 2 or the words need to appear in at least 2 tweets\n",
    "#ngram_range: (1, 2), both single words as bi-grams are used\n",
    "#clf__alpha: 0.75\n",
    "textcountscols = ['count_capital_words','count_emojis','count_excl_quest_marks','count_hashtags'\n",
    "                      ,'count_mentions','count_urls','count_words']\n",
    "    \n",
    "features = FeatureUnion([('textcounts', ColumnExtractor(cols=textcountscols))\n",
    "                         , ('pipe', Pipeline([('cleantext', ColumnExtractor(cols='clean_text'))\n",
    "                                              , ('vect', CountVectorizer(max_df=0.25, min_df=1, ngram_range=(1,2)))]))]\n",
    "                       , n_jobs=-1)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('features', features)\n",
    "    , ('clf', MultinomialNB(alpha=0.75))\n",
    "])\n",
    "\n",
    "best_model = pipeline.fit(df_model.drop('sentiment', axis=1), df_model.sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['positive', 'positive', 'positive']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_model_pos = pd.read_pickle('df_model_pos.p')\n",
    "best_model.predict(df_model_pos).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['negative', 'negative', 'negative', 'neutral']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_model_neg = pd.read_pickle('df_model_neg.p')\n",
    "best_model.predict(df_model_neg).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
