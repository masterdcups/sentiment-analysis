{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "import os\n",
    "from time import time\n",
    "from pprint import pprint\n",
    "import collections\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style=\"darkgrid\")\n",
    "sns.set(font_scale=1.3)\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "np.random.seed(37)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model = pd.read_pickle('../data/pickle_emotion/df_model_en_.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count_words</th>\n",
       "      <th>count_mentions</th>\n",
       "      <th>count_hashtags</th>\n",
       "      <th>count_capital_words</th>\n",
       "      <th>count_excl_quest_marks</th>\n",
       "      <th>count_urls</th>\n",
       "      <th>count_emojis</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>origin_text</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>joy</td>\n",
       "      <td>Happy to share my new video preview with some of my local fav's!\\n#compose #excitement @CBCMusic @Musicyyc  @CJSW @BreakOutWest @HifiClub</td>\n",
       "      <td>happy share new video preview local fav compose excitement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>anticipation</td>\n",
       "      <td>@FieldYates @MatthewBerryTMR @Stephania_ESPN @MikeClayNFL @FrankCaliendo goddamn...the 'celebrity' draft at the end was classic.</td>\n",
       "      <td>goddamn celebrity draft end classic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>pessimism</td>\n",
       "      <td>Dreams dashed and divided like million stars in the night sky.</td>\n",
       "      <td>dreams dashed divided like million stars night sky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>joy</td>\n",
       "      <td>Accept the challenges so that you can literally even feel the exhilaration of victory.' -- George S. Patton üê∂</td>\n",
       "      <td>accept challenges literally even feel exhilaration victory george patton dogface</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>joy</td>\n",
       "      <td>Happy birthday to ma brother from another mother @Official1Cedi dis year More blessing #Break itz</td>\n",
       "      <td>happy birthday brother another mother dis year blessing break itz</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   count_words  count_mentions  count_hashtags  count_capital_words  \\\n",
       "0  22           5               2               1                     \n",
       "1  14           5               0               0                     \n",
       "2  11           0               0               0                     \n",
       "3  17           0               0               0                     \n",
       "4  15           1               1               0                     \n",
       "\n",
       "   count_excl_quest_marks  count_urls  count_emojis     sentiment  \\\n",
       "0  1                       0           0             joy            \n",
       "1  0                       0           0             anticipation   \n",
       "2  0                       0           0             pessimism      \n",
       "3  0                       0           1             joy            \n",
       "4  0                       0           0             joy            \n",
       "\n",
       "                                                                                                                                 origin_text  \\\n",
       "0  Happy to share my new video preview with some of my local fav's!\\n#compose #excitement @CBCMusic @Musicyyc  @CJSW @BreakOutWest @HifiClub   \n",
       "1  @FieldYates @MatthewBerryTMR @Stephania_ESPN @MikeClayNFL @FrankCaliendo goddamn...the 'celebrity' draft at the end was classic.            \n",
       "2  Dreams dashed and divided like million stars in the night sky.                                                                              \n",
       "3  Accept the challenges so that you can literally even feel the exhilaration of victory.' -- George S. Patton üê∂                               \n",
       "4  Happy birthday to ma brother from another mother @Official1Cedi dis year More blessing #Break itz                                           \n",
       "\n",
       "                                                                         clean_text  \n",
       "0  happy share new video preview local fav compose excitement                        \n",
       "1  goddamn celebrity draft end classic                                               \n",
       "2  dreams dashed divided like million stars night sky                                \n",
       "3  accept challenges literally even feel exhilaration victory george patton dogface  \n",
       "4  happy birthday brother another mother dis year blessing break itz                 "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_model.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_model.drop('sentiment', axis=1), df_model.sentiment, test_size=0.1, random_state=37)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColumnExtractor(TransformerMixin, BaseEstimator):\n",
    "    def __init__(self, cols):\n",
    "        self.cols = cols\n",
    "\n",
    "    def transform(self, X, **transform_params):\n",
    "        return X[self.cols]\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_vect(clf, parameters_clf, X_train, X_test, parameters_text=None, vect=None):\n",
    "    \n",
    "    textcountscols = ['count_capital_words','count_emojis','count_excl_quest_marks','count_hashtags'\n",
    "                      ,'count_mentions','count_urls','count_words']\n",
    "    \n",
    "\n",
    "    features = FeatureUnion([('textcounts', ColumnExtractor(cols=textcountscols))\n",
    "                            , ('pipe', Pipeline([('cleantext', ColumnExtractor(cols='clean_text')), ('vect', vect)]))]\n",
    "                            , n_jobs=-1)\n",
    "\n",
    "    \n",
    "    pipeline = Pipeline([\n",
    "        ('features', features)\n",
    "        , ('clf', clf)\n",
    "    ])\n",
    "    \n",
    "    # Join the parameters dictionaries together\n",
    "    parameters = dict()\n",
    "    if parameters_text:\n",
    "        parameters.update(parameters_text)\n",
    "    parameters.update(parameters_clf)\n",
    "\n",
    "    # initiate gridsearchCV with parameters and pipline\n",
    "    grid_search = GridSearchCV(pipeline, parameters, n_jobs=-1, verbose=1, cv=5)\n",
    "    \n",
    "    print(\"Performing grid search...\")\n",
    "    print(\"pipeline:\", [name for name, _ in pipeline.steps])\n",
    "    print(\"parameters:\")\n",
    "    pprint(parameters)\n",
    "\n",
    "    t0 = time()\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    print(\"done in %0.3fs\" % (time() - t0))\n",
    "    print()\n",
    "\n",
    "    print(\"Best CV score: %0.3f\" % grid_search.best_score_)\n",
    "    print(\"Best parameters set:\")\n",
    "    best_parameters = grid_search.best_estimator_.get_params()\n",
    "    for param_name in sorted(parameters.keys()):\n",
    "        print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "        \n",
    "    print(\"Test score with best_estimator_: %0.3f\" % grid_search.best_estimator_.score(X_test, y_test))\n",
    "    print(\"\\n\")\n",
    "    print(\"Classification Report Test Data\")\n",
    "    print(classification_report(y_test, grid_search.best_estimator_.predict(X_test)))\n",
    "\n",
    "    print(\"all results\")\n",
    "    means = grid_search.cv_results_['mean_test_score']\n",
    "    stds = grid_search.cv_results_['std_test_score']\n",
    "    params = grid_search.cv_results_['params']\n",
    "    for mean, stdev, param in zip(means, stds, params):\n",
    "        print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "    \n",
    "    return grid_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter grid settings for the vectorizers (Count and TFIDF)\n",
    "parameters_vect = {\n",
    "    'features__pipe__vect__max_df': (0.25, 0.5, 0.75),\n",
    "    'features__pipe__vect__ngram_range': ((1, 1), (1, 2)),\n",
    "    'features__pipe__vect__min_df': (1,2)\n",
    "}\n",
    "\n",
    "# Parameter grid settings for MultinomialNB\n",
    "parameters_mnb = {\n",
    "    'clf__alpha': (0.25, 0.5, 0.75)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "countvect = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "pipeline: ['features', 'clf']\n",
      "parameters:\n",
      "{'clf__alpha': (0.25, 0.5, 0.75),\n",
      " 'features__pipe__vect__max_df': (0.25, 0.5, 0.75),\n",
      " 'features__pipe__vect__min_df': (1, 2),\n",
      " 'features__pipe__vect__ngram_range': ((1, 1), (1, 2))}\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   10.3s\n",
      "[Parallel(n_jobs=-1)]: Done 180 out of 180 | elapsed:   35.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 36.003s\n",
      "\n",
      "Best CV score: 0.568\n",
      "Best parameters set:\n",
      "\tclf__alpha: 0.75\n",
      "\tfeatures__pipe__vect__max_df: 0.25\n",
      "\tfeatures__pipe__vect__min_df: 2\n",
      "\tfeatures__pipe__vect__ngram_range: (1, 1)\n",
      "Test score with best_estimator_: 0.594\n",
      "\n",
      "\n",
      "Classification Report Test Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.61      0.89      0.72       292\n",
      "anticipation       0.24      0.11      0.15        76\n",
      "     disgust       0.29      0.04      0.07        52\n",
      "        fear       0.44      0.25      0.32        60\n",
      "         joy       0.66      0.77      0.71       203\n",
      "        love       0.00      0.00      0.00         4\n",
      "    optimism       0.00      0.00      0.00        20\n",
      "   pessimism       0.00      0.00      0.00        21\n",
      "     sadness       0.00      0.00      0.00        16\n",
      "\n",
      "   micro avg       0.59      0.59      0.59       744\n",
      "   macro avg       0.25      0.23      0.22       744\n",
      "weighted avg       0.50      0.59      0.52       744\n",
      "\n",
      "all results\n",
      "0.553481 (0.005900) with: {'clf__alpha': 0.25, 'features__pipe__vect__max_df': 0.25, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.536002 (0.004338) with: {'clf__alpha': 0.25, 'features__pipe__vect__max_df': 0.25, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.549597 (0.002395) with: {'clf__alpha': 0.25, 'features__pipe__vect__max_df': 0.25, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.558411 (0.006609) with: {'clf__alpha': 0.25, 'features__pipe__vect__max_df': 0.25, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.553481 (0.005900) with: {'clf__alpha': 0.25, 'features__pipe__vect__max_df': 0.5, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.536002 (0.004338) with: {'clf__alpha': 0.25, 'features__pipe__vect__max_df': 0.5, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.549597 (0.002395) with: {'clf__alpha': 0.25, 'features__pipe__vect__max_df': 0.5, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.558411 (0.006609) with: {'clf__alpha': 0.25, 'features__pipe__vect__max_df': 0.5, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.553481 (0.005900) with: {'clf__alpha': 0.25, 'features__pipe__vect__max_df': 0.75, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.536002 (0.004338) with: {'clf__alpha': 0.25, 'features__pipe__vect__max_df': 0.75, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.549597 (0.002395) with: {'clf__alpha': 0.25, 'features__pipe__vect__max_df': 0.75, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.558411 (0.006609) with: {'clf__alpha': 0.25, 'features__pipe__vect__max_df': 0.75, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.558859 (0.007767) with: {'clf__alpha': 0.5, 'features__pipe__vect__max_df': 0.25, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.519122 (0.007130) with: {'clf__alpha': 0.5, 'features__pipe__vect__max_df': 0.25, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.567224 (0.007977) with: {'clf__alpha': 0.5, 'features__pipe__vect__max_df': 0.25, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.565133 (0.008178) with: {'clf__alpha': 0.5, 'features__pipe__vect__max_df': 0.25, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.558859 (0.007767) with: {'clf__alpha': 0.5, 'features__pipe__vect__max_df': 0.5, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.519122 (0.007130) with: {'clf__alpha': 0.5, 'features__pipe__vect__max_df': 0.5, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.567224 (0.007977) with: {'clf__alpha': 0.5, 'features__pipe__vect__max_df': 0.5, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.565133 (0.008178) with: {'clf__alpha': 0.5, 'features__pipe__vect__max_df': 0.5, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.558859 (0.007767) with: {'clf__alpha': 0.5, 'features__pipe__vect__max_df': 0.75, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.519122 (0.007130) with: {'clf__alpha': 0.5, 'features__pipe__vect__max_df': 0.75, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.567224 (0.007977) with: {'clf__alpha': 0.5, 'features__pipe__vect__max_df': 0.75, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.565133 (0.008178) with: {'clf__alpha': 0.5, 'features__pipe__vect__max_df': 0.75, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.552136 (0.007516) with: {'clf__alpha': 0.75, 'features__pipe__vect__max_df': 0.25, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.503585 (0.005829) with: {'clf__alpha': 0.75, 'features__pipe__vect__max_df': 0.25, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.567673 (0.010479) with: {'clf__alpha': 0.75, 'features__pipe__vect__max_df': 0.25, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.557962 (0.007975) with: {'clf__alpha': 0.75, 'features__pipe__vect__max_df': 0.25, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.552136 (0.007516) with: {'clf__alpha': 0.75, 'features__pipe__vect__max_df': 0.5, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.503585 (0.005829) with: {'clf__alpha': 0.75, 'features__pipe__vect__max_df': 0.5, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.567673 (0.010479) with: {'clf__alpha': 0.75, 'features__pipe__vect__max_df': 0.5, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.557962 (0.007975) with: {'clf__alpha': 0.75, 'features__pipe__vect__max_df': 0.5, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.552136 (0.007516) with: {'clf__alpha': 0.75, 'features__pipe__vect__max_df': 0.75, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.503585 (0.005829) with: {'clf__alpha': 0.75, 'features__pipe__vect__max_df': 0.75, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.567673 (0.010479) with: {'clf__alpha': 0.75, 'features__pipe__vect__max_df': 0.75, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.557962 (0.007975) with: {'clf__alpha': 0.75, 'features__pipe__vect__max_df': 0.75, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 2)}\n"
     ]
    }
   ],
   "source": [
    "# MultinomialNB\n",
    "best_mnb_countvect = grid_vect(mnb, parameters_mnb, X_train, X_test, parameters_text=parameters_vect, vect=countvect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidfvect = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "pipeline: ['features', 'clf']\n",
      "parameters:\n",
      "{'clf__alpha': (0.25, 0.5, 0.75),\n",
      " 'features__pipe__vect__max_df': (0.25, 0.5, 0.75),\n",
      " 'features__pipe__vect__min_df': (1, 2),\n",
      " 'features__pipe__vect__ngram_range': ((1, 1), (1, 2))}\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    7.6s\n",
      "[Parallel(n_jobs=-1)]: Done 180 out of 180 | elapsed:   33.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 33.733s\n",
      "\n",
      "Best CV score: 0.543\n",
      "Best parameters set:\n",
      "\tclf__alpha: 0.25\n",
      "\tfeatures__pipe__vect__max_df: 0.25\n",
      "\tfeatures__pipe__vect__min_df: 2\n",
      "\tfeatures__pipe__vect__ngram_range: (1, 1)\n",
      "Test score with best_estimator_: 0.566\n",
      "\n",
      "\n",
      "Classification Report Test Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.56      0.90      0.69       292\n",
      "anticipation       0.20      0.05      0.08        76\n",
      "     disgust       0.25      0.02      0.04        52\n",
      "        fear       0.44      0.12      0.18        60\n",
      "         joy       0.63      0.72      0.68       203\n",
      "        love       0.00      0.00      0.00         4\n",
      "    optimism       0.00      0.00      0.00        20\n",
      "   pessimism       0.00      0.00      0.00        21\n",
      "     sadness       0.00      0.00      0.00        16\n",
      "\n",
      "   micro avg       0.57      0.57      0.57       744\n",
      "   macro avg       0.23      0.20      0.19       744\n",
      "weighted avg       0.46      0.57      0.48       744\n",
      "\n",
      "all results\n",
      "0.524649 (0.008566) with: {'clf__alpha': 0.25, 'features__pipe__vect__max_df': 0.25, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.460412 (0.009418) with: {'clf__alpha': 0.25, 'features__pipe__vect__max_df': 0.25, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.543173 (0.010066) with: {'clf__alpha': 0.25, 'features__pipe__vect__max_df': 0.25, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.530624 (0.010105) with: {'clf__alpha': 0.25, 'features__pipe__vect__max_df': 0.25, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.524649 (0.008566) with: {'clf__alpha': 0.25, 'features__pipe__vect__max_df': 0.5, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.460412 (0.009418) with: {'clf__alpha': 0.25, 'features__pipe__vect__max_df': 0.5, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.543173 (0.010066) with: {'clf__alpha': 0.25, 'features__pipe__vect__max_df': 0.5, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.530624 (0.010105) with: {'clf__alpha': 0.25, 'features__pipe__vect__max_df': 0.5, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.524649 (0.008566) with: {'clf__alpha': 0.25, 'features__pipe__vect__max_df': 0.75, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.460412 (0.009418) with: {'clf__alpha': 0.25, 'features__pipe__vect__max_df': 0.75, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.543173 (0.010066) with: {'clf__alpha': 0.25, 'features__pipe__vect__max_df': 0.75, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.530624 (0.010105) with: {'clf__alpha': 0.25, 'features__pipe__vect__max_df': 0.75, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.488796 (0.007525) with: {'clf__alpha': 0.5, 'features__pipe__vect__max_df': 0.25, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.411861 (0.004384) with: {'clf__alpha': 0.5, 'features__pipe__vect__max_df': 0.25, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.524500 (0.009661) with: {'clf__alpha': 0.5, 'features__pipe__vect__max_df': 0.25, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.495967 (0.009589) with: {'clf__alpha': 0.5, 'features__pipe__vect__max_df': 0.25, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.488796 (0.007525) with: {'clf__alpha': 0.5, 'features__pipe__vect__max_df': 0.5, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.411861 (0.004384) with: {'clf__alpha': 0.5, 'features__pipe__vect__max_df': 0.5, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.524500 (0.009661) with: {'clf__alpha': 0.5, 'features__pipe__vect__max_df': 0.5, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.495967 (0.009589) with: {'clf__alpha': 0.5, 'features__pipe__vect__max_df': 0.5, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.488796 (0.007525) with: {'clf__alpha': 0.5, 'features__pipe__vect__max_df': 0.75, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.411861 (0.004384) with: {'clf__alpha': 0.5, 'features__pipe__vect__max_df': 0.75, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.524500 (0.009661) with: {'clf__alpha': 0.5, 'features__pipe__vect__max_df': 0.75, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.495967 (0.009589) with: {'clf__alpha': 0.5, 'features__pipe__vect__max_df': 0.75, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.456229 (0.009406) with: {'clf__alpha': 0.75, 'features__pipe__vect__max_df': 0.25, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.395130 (0.002887) with: {'clf__alpha': 0.75, 'features__pipe__vect__max_df': 0.25, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.503436 (0.007962) with: {'clf__alpha': 0.75, 'features__pipe__vect__max_df': 0.25, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.471616 (0.008547) with: {'clf__alpha': 0.75, 'features__pipe__vect__max_df': 0.25, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.456229 (0.009406) with: {'clf__alpha': 0.75, 'features__pipe__vect__max_df': 0.5, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.395130 (0.002887) with: {'clf__alpha': 0.75, 'features__pipe__vect__max_df': 0.5, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.503436 (0.007962) with: {'clf__alpha': 0.75, 'features__pipe__vect__max_df': 0.5, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.471616 (0.008547) with: {'clf__alpha': 0.75, 'features__pipe__vect__max_df': 0.5, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.456229 (0.009406) with: {'clf__alpha': 0.75, 'features__pipe__vect__max_df': 0.75, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.395130 (0.002887) with: {'clf__alpha': 0.75, 'features__pipe__vect__max_df': 0.75, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.503436 (0.007962) with: {'clf__alpha': 0.75, 'features__pipe__vect__max_df': 0.75, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.471616 (0.008547) with: {'clf__alpha': 0.75, 'features__pipe__vect__max_df': 0.75, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 2)}\n"
     ]
    }
   ],
   "source": [
    "best_mnb_tfidf = grid_vect(mnb, parameters_mnb, X_train, X_test, parameters_text=parameters_vect, vect=tfidfvect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#max_df: 0.25 or maximum document frequency of 25%.\n",
    "#min_df: 2 or the words need to appear in at least 2 tweets\n",
    "#ngram_range: (1, 1)\n",
    "#clf__alpha: 0.75\n",
    "textcountscols = ['count_capital_words','count_emojis','count_excl_quest_marks','count_hashtags'\n",
    "                      ,'count_mentions','count_urls','count_words']\n",
    "    \n",
    "features = FeatureUnion([('textcounts', ColumnExtractor(cols=textcountscols))\n",
    "                         , ('pipe', Pipeline([('cleantext', ColumnExtractor(cols='clean_text'))\n",
    "                                              , ('vect', CountVectorizer(max_df=0.25, min_df=2, ngram_range=(1,1)))]))]\n",
    "                       , n_jobs=-1)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('features', features)\n",
    "    , ('clf', MultinomialNB(alpha=0.75))\n",
    "])\n",
    "\n",
    "best_model = pipeline.fit(df_model.drop('sentiment', axis=1), df_model.sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['joy', 'joy', 'anger']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_model_joy = pd.read_pickle('../data/df_model_joy.p')\n",
    "best_model.predict(df_model_joy).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['anger', 'anger', 'anger']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_model_anger = pd.read_pickle('../data/df_model_anger.p')\n",
    "best_model.predict(df_model_anger).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['joy']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_model_love = pd.read_pickle('../data/df_model_love.p')\n",
    "best_model.predict(df_model_love).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['anger']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_model_fear = pd.read_pickle('../data/df_model_fear.p')\n",
    "best_model.predict(df_model_fear).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
