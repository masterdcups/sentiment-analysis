{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "import os\n",
    "from time import time\n",
    "from pprint import pprint\n",
    "import collections\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style=\"darkgrid\")\n",
    "sns.set(font_scale=1.3)\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "np.random.seed(37)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model = pd.read_pickle('df_model.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count_words</th>\n",
       "      <th>count_mentions</th>\n",
       "      <th>count_hashtags</th>\n",
       "      <th>count_capital_words</th>\n",
       "      <th>count_excl_quest_marks</th>\n",
       "      <th>count_urls</th>\n",
       "      <th>count_emojis</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>origin_text</th>\n",
       "      <th>likes</th>\n",
       "      <th>retweets</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>557219</th>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>neutral</td>\n",
       "      <td>5 ways Internet of things will create new  opportunities for Indian businesses!Read here http://t.co/NiroT9Xa9I #DigitalUniverseIN @emcindia</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>way internet thing creat new opportun indian busi read digitaluniversein</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5084791</th>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>neutral</td>\n",
       "      <td>As #bigdata, #cloud, and #IoT usage increases, so do #security concerns https://t.co/lXwuN7CP6s  via @ITProPortal https://t.co/8KPv2ZbcuY</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>bigdata cloud iot usag increas secur concern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4330044</th>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Hewlett Packard Enterprise Co Launches an Internet of Things Platform https://t.co/qf8qKwAhFs #iot</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>hewlett packard enterpris co launch internet thing platform iot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4846444</th>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>neutral</td>\n",
       "      <td>The Internet of Things is about to disrupt the digital economy, report says https://t.co/RFWzNYvNY1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>internet thing disrupt digit economi report say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1338071</th>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>neutral</td>\n",
       "      <td>How the #InternetOfThings is changing the World around Us http://t.co/iPz10oo7hc … #IoT</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>internetofth chang world around us iot</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         count_words  count_mentions  count_hashtags  count_capital_words  \\\n",
       "557219   20           1               1               0                     \n",
       "5084791  21           1               4               0                     \n",
       "4330044  15           0               1               0                     \n",
       "4846444  17           0               0               0                     \n",
       "1338071  14           0               2               0                     \n",
       "\n",
       "         count_excl_quest_marks  count_urls  count_emojis sentiment  \\\n",
       "557219   1                       1           0             neutral    \n",
       "5084791  0                       2           0             neutral    \n",
       "4330044  0                       1           0             neutral    \n",
       "4846444  0                       1           0             neutral    \n",
       "1338071  0                       1           0             neutral    \n",
       "\n",
       "                                                                                                                                          origin_text  \\\n",
       "557219   5 ways Internet of things will create new  opportunities for Indian businesses!Read here http://t.co/NiroT9Xa9I #DigitalUniverseIN @emcindia   \n",
       "5084791  As #bigdata, #cloud, and #IoT usage increases, so do #security concerns https://t.co/lXwuN7CP6s  via @ITProPortal https://t.co/8KPv2ZbcuY      \n",
       "4330044  Hewlett Packard Enterprise Co Launches an Internet of Things Platform https://t.co/qf8qKwAhFs #iot                                             \n",
       "4846444  The Internet of Things is about to disrupt the digital economy, report says https://t.co/RFWzNYvNY1                                            \n",
       "1338071  How the #InternetOfThings is changing the World around Us http://t.co/iPz10oo7hc … #IoT                                                        \n",
       "\n",
       "        likes  retweets  \\\n",
       "557219   0     0          \n",
       "5084791  0     0          \n",
       "4330044  1     0          \n",
       "4846444  0     1          \n",
       "1338071  0     0          \n",
       "\n",
       "                                                                       clean_text  \n",
       "557219   way internet thing creat new opportun indian busi read digitaluniversein  \n",
       "5084791  bigdata cloud iot usag increas secur concern                              \n",
       "4330044  hewlett packard enterpris co launch internet thing platform iot           \n",
       "4846444  internet thing disrupt digit economi report say                           \n",
       "1338071  internetofth chang world around us iot                                    "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_model.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_model.drop('sentiment', axis=1), df_model.sentiment, test_size=0.1, random_state=37)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColumnExtractor(TransformerMixin, BaseEstimator):\n",
    "    def __init__(self, cols):\n",
    "        self.cols = cols\n",
    "\n",
    "    def transform(self, X, **transform_params):\n",
    "        return X[self.cols]\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_vect(clf, parameters_clf, X_train, X_test, parameters_text=None, vect=None):\n",
    "    \n",
    "    textcountscols = ['count_capital_words','count_emojis','count_excl_quest_marks','count_hashtags'\n",
    "                      ,'count_mentions','count_urls','count_words']\n",
    "    \n",
    "\n",
    "    features = FeatureUnion([('textcounts', ColumnExtractor(cols=textcountscols))\n",
    "                            , ('pipe', Pipeline([('cleantext', ColumnExtractor(cols='clean_text')), ('vect', vect)]))]\n",
    "                            , n_jobs=-1)\n",
    "\n",
    "    \n",
    "    pipeline = Pipeline([\n",
    "        ('features', features)\n",
    "        , ('clf', clf)\n",
    "    ])\n",
    "    \n",
    "    # Join the parameters dictionaries together\n",
    "    parameters = dict()\n",
    "    if parameters_text:\n",
    "        parameters.update(parameters_text)\n",
    "    parameters.update(parameters_clf)\n",
    "\n",
    "    # initiate gridsearchCV with parameters and pipline\n",
    "    grid_search = GridSearchCV(pipeline, parameters, n_jobs=-1, verbose=1, cv=5)\n",
    "    \n",
    "    print(\"Performing grid search...\")\n",
    "    print(\"pipeline:\", [name for name, _ in pipeline.steps])\n",
    "    print(\"parameters:\")\n",
    "    pprint(parameters)\n",
    "\n",
    "    t0 = time()\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    print(\"done in %0.3fs\" % (time() - t0))\n",
    "    print()\n",
    "\n",
    "    print(\"Best CV score: %0.3f\" % grid_search.best_score_)\n",
    "    print(\"Best parameters set:\")\n",
    "    best_parameters = grid_search.best_estimator_.get_params()\n",
    "    for param_name in sorted(parameters.keys()):\n",
    "        print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "        \n",
    "    print(\"Test score with best_estimator_: %0.3f\" % grid_search.best_estimator_.score(X_test, y_test))\n",
    "    print(\"\\n\")\n",
    "    print(\"Classification Report Test Data\")\n",
    "    print(classification_report(y_test, grid_search.best_estimator_.predict(X_test)))\n",
    "\n",
    "    print(\"all results\")\n",
    "    means = grid_search.cv_results_['mean_test_score']\n",
    "    stds = grid_search.cv_results_['std_test_score']\n",
    "    params = grid_search.cv_results_['params']\n",
    "    for mean, stdev, param in zip(means, stds, params):\n",
    "        print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "    \n",
    "    return grid_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter grid settings for the vectorizers (Count and TFIDF)\n",
    "parameters_vect = {\n",
    "    'features__pipe__vect__max_df': (0.25, 0.5, 0.75),\n",
    "    'features__pipe__vect__ngram_range': ((1, 1), (1, 2)),\n",
    "    'features__pipe__vect__min_df': (1,2)\n",
    "}\n",
    "\n",
    "# Parameter grid settings for MultinomialNB\n",
    "parameters_mnb = {\n",
    "    'clf__alpha': (0.25, 0.5, 0.75)\n",
    "}\n",
    "# Parameter grid settings for LogisticRegression\n",
    "parameters_lg = {\n",
    "    'clf__C': (0.25, 0.5, 1.0),\n",
    "    'clf__penalty': ('l1', 'l2')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lg = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "countvect = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "pipeline: ['features', 'clf']\n",
      "parameters:\n",
      "{'clf__C': (0.25, 0.5, 1.0),\n",
      " 'clf__penalty': ('l1', 'l2'),\n",
      " 'features__pipe__vect__max_df': (0.25, 0.5, 0.75),\n",
      " 'features__pipe__vect__min_df': (1, 2),\n",
      " 'features__pipe__vect__ngram_range': ((1, 1), (1, 2))}\n",
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed: 13.1min\n",
      "[Parallel(n_jobs=-1)]: Done 360 out of 360 | elapsed: 29.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 1808.524s\n",
      "\n",
      "Best CV score: 0.809\n",
      "Best parameters set:\n",
      "\tclf__C: 1.0\n",
      "\tclf__penalty: 'l2'\n",
      "\tfeatures__pipe__vect__max_df: 0.75\n",
      "\tfeatures__pipe__vect__min_df: 1\n",
      "\tfeatures__pipe__vect__ngram_range: (1, 2)\n",
      "Test score with best_estimator_: 0.815\n",
      "\n",
      "\n",
      "Classification Report Test Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.82      0.83      1333\n",
      "     neutral       0.79      0.80      0.80      1884\n",
      "    positive       0.82      0.83      0.82      1730\n",
      "\n",
      "   micro avg       0.81      0.81      0.81      4947\n",
      "   macro avg       0.82      0.82      0.82      4947\n",
      "weighted avg       0.82      0.81      0.81      4947\n",
      "\n",
      "all results\n",
      "0.750595 (0.003347) with: {'clf__C': 0.25, 'clf__penalty': 'l1', 'features__pipe__vect__max_df': 0.25, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.773573 (0.004833) with: {'clf__C': 0.25, 'clf__penalty': 'l1', 'features__pipe__vect__max_df': 0.25, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.750550 (0.003339) with: {'clf__C': 0.25, 'clf__penalty': 'l1', 'features__pipe__vect__max_df': 0.25, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.773573 (0.004786) with: {'clf__C': 0.25, 'clf__penalty': 'l1', 'features__pipe__vect__max_df': 0.25, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.760478 (0.002675) with: {'clf__C': 0.25, 'clf__penalty': 'l1', 'features__pipe__vect__max_df': 0.5, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.778873 (0.005188) with: {'clf__C': 0.25, 'clf__penalty': 'l1', 'features__pipe__vect__max_df': 0.5, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.760500 (0.002686) with: {'clf__C': 0.25, 'clf__penalty': 'l1', 'features__pipe__vect__max_df': 0.5, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.778896 (0.005266) with: {'clf__C': 0.25, 'clf__penalty': 'l1', 'features__pipe__vect__max_df': 0.5, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.761039 (0.001482) with: {'clf__C': 0.25, 'clf__penalty': 'l1', 'features__pipe__vect__max_df': 0.75, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.777930 (0.004961) with: {'clf__C': 0.25, 'clf__penalty': 'l1', 'features__pipe__vect__max_df': 0.75, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.761062 (0.001456) with: {'clf__C': 0.25, 'clf__penalty': 'l1', 'features__pipe__vect__max_df': 0.75, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.777930 (0.004962) with: {'clf__C': 0.25, 'clf__penalty': 'l1', 'features__pipe__vect__max_df': 0.75, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.762522 (0.002416) with: {'clf__C': 0.25, 'clf__penalty': 'l2', 'features__pipe__vect__max_df': 0.25, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.799380 (0.004022) with: {'clf__C': 0.25, 'clf__penalty': 'l2', 'features__pipe__vect__max_df': 0.25, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.761826 (0.002087) with: {'clf__C': 0.25, 'clf__penalty': 'l2', 'features__pipe__vect__max_df': 0.25, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.799133 (0.005138) with: {'clf__C': 0.25, 'clf__penalty': 'l2', 'features__pipe__vect__max_df': 0.25, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.773348 (0.002858) with: {'clf__C': 0.25, 'clf__penalty': 'l2', 'features__pipe__vect__max_df': 0.5, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.802570 (0.005913) with: {'clf__C': 0.25, 'clf__penalty': 'l2', 'features__pipe__vect__max_df': 0.5, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.772831 (0.002914) with: {'clf__C': 0.25, 'clf__penalty': 'l2', 'features__pipe__vect__max_df': 0.5, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.801536 (0.006172) with: {'clf__C': 0.25, 'clf__penalty': 'l2', 'features__pipe__vect__max_df': 0.5, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.773887 (0.002263) with: {'clf__C': 0.25, 'clf__penalty': 'l2', 'features__pipe__vect__max_df': 0.75, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.802165 (0.005988) with: {'clf__C': 0.25, 'clf__penalty': 'l2', 'features__pipe__vect__max_df': 0.75, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.773393 (0.002834) with: {'clf__C': 0.25, 'clf__penalty': 'l2', 'features__pipe__vect__max_df': 0.75, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.801581 (0.005841) with: {'clf__C': 0.25, 'clf__penalty': 'l2', 'features__pipe__vect__max_df': 0.75, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.761331 (0.002084) with: {'clf__C': 0.5, 'clf__penalty': 'l1', 'features__pipe__vect__max_df': 0.25, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.790351 (0.006061) with: {'clf__C': 0.5, 'clf__penalty': 'l1', 'features__pipe__vect__max_df': 0.25, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.761354 (0.001978) with: {'clf__C': 0.5, 'clf__penalty': 'l1', 'features__pipe__vect__max_df': 0.25, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.790283 (0.006049) with: {'clf__C': 0.5, 'clf__penalty': 'l1', 'features__pipe__vect__max_df': 0.25, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.771888 (0.002806) with: {'clf__C': 0.5, 'clf__penalty': 'l1', 'features__pipe__vect__max_df': 0.5, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.793203 (0.006264) with: {'clf__C': 0.5, 'clf__penalty': 'l1', 'features__pipe__vect__max_df': 0.5, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.771798 (0.002807) with: {'clf__C': 0.5, 'clf__penalty': 'l1', 'features__pipe__vect__max_df': 0.5, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.793136 (0.006154) with: {'clf__C': 0.5, 'clf__penalty': 'l1', 'features__pipe__vect__max_df': 0.5, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.772652 (0.001774) with: {'clf__C': 0.5, 'clf__penalty': 'l1', 'features__pipe__vect__max_df': 0.75, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.794281 (0.006070) with: {'clf__C': 0.5, 'clf__penalty': 'l1', 'features__pipe__vect__max_df': 0.75, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.772719 (0.001737) with: {'clf__C': 0.5, 'clf__penalty': 'l1', 'features__pipe__vect__max_df': 0.75, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.794349 (0.006071) with: {'clf__C': 0.5, 'clf__penalty': 'l1', 'features__pipe__vect__max_df': 0.75, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.765756 (0.002524) with: {'clf__C': 0.5, 'clf__penalty': 'l2', 'features__pipe__vect__max_df': 0.25, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.803895 (0.004490) with: {'clf__C': 0.5, 'clf__penalty': 'l2', 'features__pipe__vect__max_df': 0.25, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.764903 (0.002352) with: {'clf__C': 0.5, 'clf__penalty': 'l2', 'features__pipe__vect__max_df': 0.25, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.802884 (0.004511) with: {'clf__C': 0.5, 'clf__penalty': 'l2', 'features__pipe__vect__max_df': 0.25, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.775572 (0.003243) with: {'clf__C': 0.5, 'clf__penalty': 'l2', 'features__pipe__vect__max_df': 0.5, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.806096 (0.006553) with: {'clf__C': 0.5, 'clf__penalty': 'l2', 'features__pipe__vect__max_df': 0.5, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.774561 (0.003161) with: {'clf__C': 0.5, 'clf__penalty': 'l2', 'features__pipe__vect__max_df': 0.5, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.804546 (0.005140) with: {'clf__C': 0.5, 'clf__penalty': 'l2', 'features__pipe__vect__max_df': 0.5, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.776380 (0.002283) with: {'clf__C': 0.5, 'clf__penalty': 'l2', 'features__pipe__vect__max_df': 0.75, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.806927 (0.007155) with: {'clf__C': 0.5, 'clf__penalty': 'l2', 'features__pipe__vect__max_df': 0.75, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.775504 (0.003244) with: {'clf__C': 0.5, 'clf__penalty': 'l2', 'features__pipe__vect__max_df': 0.75, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.805355 (0.005655) with: {'clf__C': 0.5, 'clf__penalty': 'l2', 'features__pipe__vect__max_df': 0.75, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.765869 (0.002611) with: {'clf__C': 1.0, 'clf__penalty': 'l1', 'features__pipe__vect__max_df': 0.25, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.798886 (0.005492) with: {'clf__C': 1.0, 'clf__penalty': 'l1', 'features__pipe__vect__max_df': 0.25, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.766048 (0.002389) with: {'clf__C': 1.0, 'clf__penalty': 'l1', 'features__pipe__vect__max_df': 0.25, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.798594 (0.005304) with: {'clf__C': 1.0, 'clf__penalty': 'l1', 'features__pipe__vect__max_df': 0.25, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.775190 (0.002609) with: {'clf__C': 1.0, 'clf__penalty': 'l1', 'features__pipe__vect__max_df': 0.5, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.801379 (0.006312) with: {'clf__C': 1.0, 'clf__penalty': 'l1', 'features__pipe__vect__max_df': 0.5, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.775190 (0.002494) with: {'clf__C': 1.0, 'clf__penalty': 'l1', 'features__pipe__vect__max_df': 0.5, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.801110 (0.006200) with: {'clf__C': 1.0, 'clf__penalty': 'l1', 'features__pipe__vect__max_df': 0.5, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.776807 (0.001617) with: {'clf__C': 1.0, 'clf__penalty': 'l1', 'features__pipe__vect__max_df': 0.75, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.801604 (0.005345) with: {'clf__C': 1.0, 'clf__penalty': 'l1', 'features__pipe__vect__max_df': 0.75, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.776627 (0.001451) with: {'clf__C': 1.0, 'clf__penalty': 'l1', 'features__pipe__vect__max_df': 0.75, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.801154 (0.005252) with: {'clf__C': 1.0, 'clf__penalty': 'l1', 'features__pipe__vect__max_df': 0.75, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.765577 (0.001312) with: {'clf__C': 1.0, 'clf__penalty': 'l2', 'features__pipe__vect__max_df': 0.25, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.806208 (0.004281) with: {'clf__C': 1.0, 'clf__penalty': 'l2', 'features__pipe__vect__max_df': 0.25, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.764117 (0.002086) with: {'clf__C': 1.0, 'clf__penalty': 'l2', 'features__pipe__vect__max_df': 0.25, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.804097 (0.004135) with: {'clf__C': 1.0, 'clf__penalty': 'l2', 'features__pipe__vect__max_df': 0.25, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.775594 (0.003212) with: {'clf__C': 1.0, 'clf__penalty': 'l2', 'features__pipe__vect__max_df': 0.5, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.808409 (0.006686) with: {'clf__C': 1.0, 'clf__penalty': 'l2', 'features__pipe__vect__max_df': 0.5, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.775055 (0.003056) with: {'clf__C': 1.0, 'clf__penalty': 'l2', 'features__pipe__vect__max_df': 0.5, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.805624 (0.005361) with: {'clf__C': 1.0, 'clf__penalty': 'l2', 'features__pipe__vect__max_df': 0.5, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.777413 (0.001965) with: {'clf__C': 1.0, 'clf__penalty': 'l2', 'features__pipe__vect__max_df': 0.75, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.809330 (0.006273) with: {'clf__C': 1.0, 'clf__penalty': 'l2', 'features__pipe__vect__max_df': 0.75, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.775864 (0.002109) with: {'clf__C': 1.0, 'clf__penalty': 'l2', 'features__pipe__vect__max_df': 0.75, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.805939 (0.004050) with: {'clf__C': 1.0, 'clf__penalty': 'l2', 'features__pipe__vect__max_df': 0.75, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 2)}\n"
     ]
    }
   ],
   "source": [
    "# LogisticRegression\n",
    "best_lg_countvect = grid_vect(lg, parameters_lg, X_train, X_test, parameters_text=parameters_vect, vect=countvect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidfvect = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "pipeline: ['features', 'clf']\n",
      "parameters:\n",
      "{'clf__C': (0.25, 0.5, 1.0),\n",
      " 'clf__penalty': ('l1', 'l2'),\n",
      " 'features__pipe__vect__max_df': (0.25, 0.5, 0.75),\n",
      " 'features__pipe__vect__min_df': (1, 2),\n",
      " 'features__pipe__vect__ngram_range': ((1, 1), (1, 2))}\n",
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   57.5s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  9.5min\n",
      "[Parallel(n_jobs=-1)]: Done 360 out of 360 | elapsed: 23.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 1458.662s\n",
      "\n",
      "Best CV score: 0.788\n",
      "Best parameters set:\n",
      "\tclf__C: 1.0\n",
      "\tclf__penalty: 'l2'\n",
      "\tfeatures__pipe__vect__max_df: 0.75\n",
      "\tfeatures__pipe__vect__min_df: 2\n",
      "\tfeatures__pipe__vect__ngram_range: (1, 2)\n",
      "Test score with best_estimator_: 0.793\n",
      "\n",
      "\n",
      "Classification Report Test Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.77      0.80      1333\n",
      "     neutral       0.76      0.79      0.77      1884\n",
      "    positive       0.81      0.82      0.81      1730\n",
      "\n",
      "   micro avg       0.79      0.79      0.79      4947\n",
      "   macro avg       0.80      0.79      0.79      4947\n",
      "weighted avg       0.79      0.79      0.79      4947\n",
      "\n",
      "all results\n",
      "0.731526 (0.004396) with: {'clf__C': 0.25, 'clf__penalty': 'l1', 'features__pipe__vect__max_df': 0.25, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.722092 (0.003060) with: {'clf__C': 0.25, 'clf__penalty': 'l1', 'features__pipe__vect__max_df': 0.25, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.732671 (0.004679) with: {'clf__C': 0.25, 'clf__penalty': 'l1', 'features__pipe__vect__max_df': 0.25, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.729325 (0.004457) with: {'clf__C': 0.25, 'clf__penalty': 'l1', 'features__pipe__vect__max_df': 0.25, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.740218 (0.002345) with: {'clf__C': 0.25, 'clf__penalty': 'l1', 'features__pipe__vect__max_df': 0.5, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.727011 (0.002793) with: {'clf__C': 0.25, 'clf__penalty': 'l1', 'features__pipe__vect__max_df': 0.5, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.740802 (0.003242) with: {'clf__C': 0.25, 'clf__penalty': 'l1', 'features__pipe__vect__max_df': 0.5, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.735232 (0.004535) with: {'clf__C': 0.25, 'clf__penalty': 'l1', 'features__pipe__vect__max_df': 0.5, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.743273 (0.002615) with: {'clf__C': 0.25, 'clf__penalty': 'l1', 'features__pipe__vect__max_df': 0.75, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.726832 (0.002125) with: {'clf__C': 0.25, 'clf__penalty': 'l1', 'features__pipe__vect__max_df': 0.75, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.744845 (0.002429) with: {'clf__C': 0.25, 'clf__penalty': 'l1', 'features__pipe__vect__max_df': 0.75, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.734895 (0.003861) with: {'clf__C': 0.25, 'clf__penalty': 'l1', 'features__pipe__vect__max_df': 0.75, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.741319 (0.002165) with: {'clf__C': 0.25, 'clf__penalty': 'l2', 'features__pipe__vect__max_df': 0.25, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.742981 (0.005929) with: {'clf__C': 0.25, 'clf__penalty': 'l2', 'features__pipe__vect__max_df': 0.25, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.742824 (0.002327) with: {'clf__C': 0.25, 'clf__penalty': 'l2', 'features__pipe__vect__max_df': 0.25, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.752527 (0.003547) with: {'clf__C': 0.25, 'clf__penalty': 'l2', 'features__pipe__vect__max_df': 0.25, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.750865 (0.003960) with: {'clf__C': 0.25, 'clf__penalty': 'l2', 'features__pipe__vect__max_df': 0.5, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.748282 (0.002330) with: {'clf__C': 0.25, 'clf__penalty': 'l2', 'features__pipe__vect__max_df': 0.5, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.752617 (0.004274) with: {'clf__C': 0.25, 'clf__penalty': 'l2', 'features__pipe__vect__max_df': 0.5, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.756031 (0.009617) with: {'clf__C': 0.25, 'clf__penalty': 'l2', 'features__pipe__vect__max_df': 0.5, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.753538 (0.002150) with: {'clf__C': 0.25, 'clf__penalty': 'l2', 'features__pipe__vect__max_df': 0.75, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.747024 (0.003422) with: {'clf__C': 0.25, 'clf__penalty': 'l2', 'features__pipe__vect__max_df': 0.75, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.756255 (0.002891) with: {'clf__C': 0.25, 'clf__penalty': 'l2', 'features__pipe__vect__max_df': 0.75, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.760680 (0.004081) with: {'clf__C': 0.25, 'clf__penalty': 'l2', 'features__pipe__vect__max_df': 0.75, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.750708 (0.002828) with: {'clf__C': 0.5, 'clf__penalty': 'l1', 'features__pipe__vect__max_df': 0.25, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.758906 (0.005268) with: {'clf__C': 0.5, 'clf__penalty': 'l1', 'features__pipe__vect__max_df': 0.25, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.751606 (0.003535) with: {'clf__C': 0.5, 'clf__penalty': 'l1', 'features__pipe__vect__max_df': 0.25, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.763330 (0.005939) with: {'clf__C': 0.5, 'clf__penalty': 'l1', 'features__pipe__vect__max_df': 0.25, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.760208 (0.002312) with: {'clf__C': 0.5, 'clf__penalty': 'l1', 'features__pipe__vect__max_df': 0.5, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.760792 (0.005227) with: {'clf__C': 0.5, 'clf__penalty': 'l1', 'features__pipe__vect__max_df': 0.5, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.761152 (0.001794) with: {'clf__C': 0.5, 'clf__penalty': 'l1', 'features__pipe__vect__max_df': 0.5, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.766430 (0.005299) with: {'clf__C': 0.5, 'clf__penalty': 'l1', 'features__pipe__vect__max_df': 0.5, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.763218 (0.001648) with: {'clf__C': 0.5, 'clf__penalty': 'l1', 'features__pipe__vect__max_df': 0.75, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.761309 (0.003386) with: {'clf__C': 0.5, 'clf__penalty': 'l1', 'features__pipe__vect__max_df': 0.75, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.764049 (0.002915) with: {'clf__C': 0.5, 'clf__penalty': 'l1', 'features__pipe__vect__max_df': 0.75, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.767643 (0.004220) with: {'clf__C': 0.5, 'clf__penalty': 'l1', 'features__pipe__vect__max_df': 0.75, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.754256 (0.002542) with: {'clf__C': 0.5, 'clf__penalty': 'l2', 'features__pipe__vect__max_df': 0.25, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.765060 (0.005061) with: {'clf__C': 0.5, 'clf__penalty': 'l2', 'features__pipe__vect__max_df': 0.25, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.753897 (0.001836) with: {'clf__C': 0.5, 'clf__penalty': 'l2', 'features__pipe__vect__max_df': 0.25, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.775212 (0.005939) with: {'clf__C': 0.5, 'clf__penalty': 'l2', 'features__pipe__vect__max_df': 0.25, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.762499 (0.005312) with: {'clf__C': 0.5, 'clf__penalty': 'l2', 'features__pipe__vect__max_df': 0.5, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.762567 (0.008130) with: {'clf__C': 0.5, 'clf__penalty': 'l2', 'features__pipe__vect__max_df': 0.5, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.765464 (0.002298) with: {'clf__C': 0.5, 'clf__penalty': 'l2', 'features__pipe__vect__max_df': 0.5, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.776672 (0.008231) with: {'clf__C': 0.5, 'clf__penalty': 'l2', 'features__pipe__vect__max_df': 0.5, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.767463 (0.002099) with: {'clf__C': 0.5, 'clf__penalty': 'l2', 'features__pipe__vect__max_df': 0.75, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.763982 (0.008293) with: {'clf__C': 0.5, 'clf__penalty': 'l2', 'features__pipe__vect__max_df': 0.75, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.768294 (0.001925) with: {'clf__C': 0.5, 'clf__penalty': 'l2', 'features__pipe__vect__max_df': 0.75, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.780783 (0.005800) with: {'clf__C': 0.5, 'clf__penalty': 'l2', 'features__pipe__vect__max_df': 0.75, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.763667 (0.002520) with: {'clf__C': 1.0, 'clf__penalty': 'l1', 'features__pipe__vect__max_df': 0.25, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.782422 (0.005742) with: {'clf__C': 1.0, 'clf__penalty': 'l1', 'features__pipe__vect__max_df': 0.25, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.763600 (0.002514) with: {'clf__C': 1.0, 'clf__penalty': 'l1', 'features__pipe__vect__max_df': 0.25, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.784511 (0.005597) with: {'clf__C': 1.0, 'clf__penalty': 'l1', 'features__pipe__vect__max_df': 0.25, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.771798 (0.003283) with: {'clf__C': 1.0, 'clf__penalty': 'l1', 'features__pipe__vect__max_df': 0.5, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.784286 (0.006352) with: {'clf__C': 1.0, 'clf__penalty': 'l1', 'features__pipe__vect__max_df': 0.5, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.772113 (0.003140) with: {'clf__C': 1.0, 'clf__penalty': 'l1', 'features__pipe__vect__max_df': 0.5, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.787274 (0.006437) with: {'clf__C': 1.0, 'clf__penalty': 'l1', 'features__pipe__vect__max_df': 0.5, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.774673 (0.002931) with: {'clf__C': 1.0, 'clf__penalty': 'l1', 'features__pipe__vect__max_df': 0.75, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.784578 (0.004714) with: {'clf__C': 1.0, 'clf__penalty': 'l1', 'features__pipe__vect__max_df': 0.75, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.774898 (0.003254) with: {'clf__C': 1.0, 'clf__penalty': 'l1', 'features__pipe__vect__max_df': 0.75, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.787431 (0.005843) with: {'clf__C': 1.0, 'clf__penalty': 'l1', 'features__pipe__vect__max_df': 0.75, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.760119 (0.002199) with: {'clf__C': 1.0, 'clf__penalty': 'l2', 'features__pipe__vect__max_df': 0.25, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.772158 (0.005296) with: {'clf__C': 1.0, 'clf__penalty': 'l2', 'features__pipe__vect__max_df': 0.25, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.758120 (0.002853) with: {'clf__C': 1.0, 'clf__penalty': 'l2', 'features__pipe__vect__max_df': 0.25, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.780783 (0.007398) with: {'clf__C': 1.0, 'clf__penalty': 'l2', 'features__pipe__vect__max_df': 0.25, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.769058 (0.004232) with: {'clf__C': 1.0, 'clf__penalty': 'l2', 'features__pipe__vect__max_df': 0.5, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.771753 (0.010600) with: {'clf__C': 1.0, 'clf__penalty': 'l2', 'features__pipe__vect__max_df': 0.5, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.767576 (0.004453) with: {'clf__C': 1.0, 'clf__penalty': 'l2', 'features__pipe__vect__max_df': 0.5, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.783770 (0.007231) with: {'clf__C': 1.0, 'clf__penalty': 'l2', 'features__pipe__vect__max_df': 0.5, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.772292 (0.002536) with: {'clf__C': 1.0, 'clf__penalty': 'l2', 'features__pipe__vect__max_df': 0.75, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.776290 (0.006084) with: {'clf__C': 1.0, 'clf__penalty': 'l2', 'features__pipe__vect__max_df': 0.75, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.773460 (0.002783) with: {'clf__C': 1.0, 'clf__penalty': 'l2', 'features__pipe__vect__max_df': 0.75, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.788329 (0.007418) with: {'clf__C': 1.0, 'clf__penalty': 'l2', 'features__pipe__vect__max_df': 0.75, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 2)}\n"
     ]
    }
   ],
   "source": [
    "best_lg_tfidf = grid_vect(lg, parameters_lg, X_train, X_test, parameters_text=parameters_vect, vect=tfidfvect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#max_df: 0.25 or maximum document frequency of 25%.\n",
    "#min_df: 2 or the words need to appear in at least 2 tweets\n",
    "#ngram_range: (1, 2), both single words as bi-grams are used\n",
    "#clf__C: 1\n",
    "#clf__penalty: l2\n",
    "textcountscols = ['count_capital_words','count_emojis','count_excl_quest_marks','count_hashtags'\n",
    "                      ,'count_mentions','count_urls','count_words']\n",
    "    \n",
    "features = FeatureUnion([('textcounts', ColumnExtractor(cols=textcountscols))\n",
    "                         , ('pipe', Pipeline([('cleantext', ColumnExtractor(cols='clean_text'))\n",
    "                                              , ('vect', CountVectorizer(max_df=0.75, min_df=1, ngram_range=(1,2)))]))]\n",
    "                       , n_jobs=-1)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('features', features)\n",
    "    , ('clf', LogisticRegression(C=1.0, penalty='l2'))\n",
    "])\n",
    "\n",
    "best_model = pipeline.fit(df_model.drop('sentiment', axis=1), df_model.sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['positive', 'positive', 'positive']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_model_pos = pd.read_pickle('df_model_pos.p')\n",
    "best_model.predict(df_model_pos).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['negative', 'positive', 'negative', 'negative']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_model_neg = pd.read_pickle('df_model_neg.p')\n",
    "best_model.predict(df_model_neg).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
