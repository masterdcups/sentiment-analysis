{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "import os\n",
    "from time import time\n",
    "from pprint import pprint\n",
    "import collections\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style=\"darkgrid\")\n",
    "sns.set(font_scale=1.3)\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "np.random.seed(37)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model = pd.read_pickle('../data/pickle_emotion/df_model_en_.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count_words</th>\n",
       "      <th>count_mentions</th>\n",
       "      <th>count_hashtags</th>\n",
       "      <th>count_capital_words</th>\n",
       "      <th>count_excl_quest_marks</th>\n",
       "      <th>count_urls</th>\n",
       "      <th>count_emojis</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>origin_text</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>fear</td>\n",
       "      <td>Now #India is #afraid of #bad .</td>\n",
       "      <td>india afraid bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>anger</td>\n",
       "      <td>He's seriously so frustrating sometimes! (‚ïØ¬∞‚ñ°¬∞Ôºâ‚ïØÔ∏µ ‚îª‚îÅ‚îª #ugh #raging</td>\n",
       "      <td>seriously frustrating sometimes ‚ïØ¬∞‚ñ°¬∞Ôºâ‚ïØÔ∏µ ‚îª‚îÅ‚îª ugh raging</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>anger</td>\n",
       "      <td>How in the world did Nicole beat Paul?!?! #terrible #bb18 #BBFinale What was the jury thinking?? üò≥üò≥üò≥</td>\n",
       "      <td>world nicole beat paul terrible bb bbfinale jury thinking üò≥üò≥üò≥</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>anger</td>\n",
       "      <td>Yeah, no. I don' mind tweetin' that twice. #snap #blm #likeThat</td>\n",
       "      <td>yeah no mind tweetin twice snap blm likethat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>joy</td>\n",
       "      <td>What's the most important thing you need to accomplish today? #onlinemarketing #solopreneur #start up #success</td>\n",
       "      <td>important thing need accomplish today onlinemarketing solopreneur start success</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   count_words  count_mentions  count_hashtags  count_capital_words  \\\n",
       "0  6            0               3               0                     \n",
       "1  8            0               2               0                     \n",
       "2  16           0               3               0                     \n",
       "3  11           0               3               0                     \n",
       "4  16           0               4               0                     \n",
       "\n",
       "   count_excl_quest_marks  count_urls  count_emojis sentiment  \\\n",
       "0  0                       0           0             fear       \n",
       "1  1                       0           0             anger      \n",
       "2  6                       0           3             anger      \n",
       "3  0                       0           0             anger      \n",
       "4  1                       0           0             joy        \n",
       "\n",
       "                                                                                                      origin_text  \\\n",
       "0  Now #India is #afraid of #bad .                                                                                  \n",
       "1  He's seriously so frustrating sometimes! (‚ïØ¬∞‚ñ°¬∞Ôºâ‚ïØÔ∏µ ‚îª‚îÅ‚îª #ugh #raging                                               \n",
       "2  How in the world did Nicole beat Paul?!?! #terrible #bb18 #BBFinale What was the jury thinking?? üò≥üò≥üò≥             \n",
       "3  Yeah, no. I don' mind tweetin' that twice. #snap #blm #likeThat                                                  \n",
       "4  What's the most important thing you need to accomplish today? #onlinemarketing #solopreneur #start up #success   \n",
       "\n",
       "                                                                        clean_text  \n",
       "0  india afraid bad                                                                 \n",
       "1  seriously frustrating sometimes ‚ïØ¬∞‚ñ°¬∞Ôºâ‚ïØÔ∏µ ‚îª‚îÅ‚îª ugh raging                           \n",
       "2  world nicole beat paul terrible bb bbfinale jury thinking üò≥üò≥üò≥                    \n",
       "3  yeah no mind tweetin twice snap blm likethat                                     \n",
       "4  important thing need accomplish today onlinemarketing solopreneur start success  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_model.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_model.drop('sentiment', axis=1), df_model.sentiment, test_size=0.1, random_state=37)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColumnExtractor(TransformerMixin, BaseEstimator):\n",
    "    def __init__(self, cols):\n",
    "        self.cols = cols\n",
    "\n",
    "    def transform(self, X, **transform_params):\n",
    "        return X[self.cols]\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_vect(clf, parameters_clf, X_train, X_test, parameters_text=None, vect=None):\n",
    "    \n",
    "    textcountscols = ['count_capital_words','count_emojis','count_excl_quest_marks','count_hashtags'\n",
    "                      ,'count_mentions','count_urls','count_words']\n",
    "    \n",
    "\n",
    "    features = FeatureUnion([('textcounts', ColumnExtractor(cols=textcountscols))\n",
    "                            , ('pipe', Pipeline([('cleantext', ColumnExtractor(cols='clean_text')), ('vect', vect)]))]\n",
    "                            , n_jobs=-1)\n",
    "\n",
    "    \n",
    "    pipeline = Pipeline([\n",
    "        ('features', features)\n",
    "        , ('clf', clf)\n",
    "    ])\n",
    "    \n",
    "    # Join the parameters dictionaries together\n",
    "    parameters = dict()\n",
    "    if parameters_text:\n",
    "        parameters.update(parameters_text)\n",
    "    parameters.update(parameters_clf)\n",
    "\n",
    "    # initiate gridsearchCV with parameters and pipline\n",
    "    grid_search = GridSearchCV(pipeline, parameters, n_jobs=-1, verbose=1, cv=5)\n",
    "    \n",
    "    print(\"Performing grid search...\")\n",
    "    print(\"pipeline:\", [name for name, _ in pipeline.steps])\n",
    "    print(\"parameters:\")\n",
    "    pprint(parameters)\n",
    "\n",
    "    t0 = time()\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    print(\"done in %0.3fs\" % (time() - t0))\n",
    "    print()\n",
    "\n",
    "    print(\"Best CV score: %0.3f\" % grid_search.best_score_)\n",
    "    print(\"Best parameters set:\")\n",
    "    best_parameters = grid_search.best_estimator_.get_params()\n",
    "    for param_name in sorted(parameters.keys()):\n",
    "        print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "        \n",
    "    print(\"Test score with best_estimator_: %0.3f\" % grid_search.best_estimator_.score(X_test, y_test))\n",
    "    print(\"\\n\")\n",
    "    print(\"Classification Report Test Data\")\n",
    "    print(classification_report(y_test, grid_search.best_estimator_.predict(X_test)))\n",
    "\n",
    "    print(\"all results\")\n",
    "    means = grid_search.cv_results_['mean_test_score']\n",
    "    stds = grid_search.cv_results_['std_test_score']\n",
    "    params = grid_search.cv_results_['params']\n",
    "    for mean, stdev, param in zip(means, stds, params):\n",
    "        print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "    \n",
    "    return grid_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter grid settings for the vectorizers (Count and TFIDF)\n",
    "parameters_vect = {\n",
    "    'features__pipe__vect__max_df': (0.25, 0.5, 0.75),\n",
    "    'features__pipe__vect__ngram_range': ((1, 1), (1, 2)),\n",
    "    'features__pipe__vect__min_df': (1,2)\n",
    "}\n",
    "\n",
    "# Parameter grid settings for MultinomialNB\n",
    "parameters_mnb = {\n",
    "    'clf__alpha': (0.25, 0.5, 0.75)\n",
    "}\n",
    "# Parameter grid settings for LogisticRegression\n",
    "parameters_lg = {\n",
    "    'clf__C': (0.25, 0.5, 1.0),\n",
    "    'clf__penalty': ('l1', 'l2')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lg = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "countvect = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "pipeline: ['features', 'clf']\n",
      "parameters:\n",
      "{'clf__C': (0.25, 0.5, 1.0),\n",
      " 'clf__penalty': ('l1', 'l2'),\n",
      " 'features__pipe__vect__max_df': (0.25, 0.5, 0.75),\n",
      " 'features__pipe__vect__min_df': (1, 2),\n",
      " 'features__pipe__vect__ngram_range': ((1, 1), (1, 2))}\n",
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   12.6s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:   56.0s\n",
      "[Parallel(n_jobs=-1)]: Done 360 out of 360 | elapsed:  2.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 119.550s\n",
      "\n",
      "Best CV score: 0.592\n",
      "Best parameters set:\n",
      "\tclf__C: 0.25\n",
      "\tclf__penalty: 'l2'\n",
      "\tfeatures__pipe__vect__max_df: 0.25\n",
      "\tfeatures__pipe__vect__min_df: 1\n",
      "\tfeatures__pipe__vect__ngram_range: (1, 1)\n",
      "Test score with best_estimator_: 0.598\n",
      "\n",
      "\n",
      "Classification Report Test Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.61      0.88      0.72       284\n",
      "anticipation       0.37      0.17      0.23        95\n",
      "     disgust       0.20      0.02      0.04        48\n",
      "        fear       0.62      0.56      0.59        66\n",
      "         joy       0.63      0.73      0.68       187\n",
      "        love       0.00      0.00      0.00         1\n",
      "    optimism       0.00      0.00      0.00        22\n",
      "   pessimism       0.56      0.31      0.40        16\n",
      "     sadness       0.00      0.00      0.00        22\n",
      "    surprise       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.60      0.60      0.60       744\n",
      "   macro avg       0.30      0.27      0.27       744\n",
      "weighted avg       0.52      0.60      0.54       744\n",
      "\n",
      "all results\n",
      "0.572304 (0.007416) with: {'clf__C': 0.25, 'clf__penalty': 'l1', 'features__pipe__vect__max_df': 0.25, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.572304 (0.007416) with: {'clf__C': 0.25, 'clf__penalty': 'l1', 'features__pipe__vect__max_df': 0.25, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.572304 (0.007416) with: {'clf__C': 0.25, 'clf__penalty': 'l1', 'features__pipe__vect__max_df': 0.25, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.572454 (0.007505) with: {'clf__C': 0.25, 'clf__penalty': 'l1', 'features__pipe__vect__max_df': 0.25, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.572304 (0.007416) with: {'clf__C': 0.25, 'clf__penalty': 'l1', 'features__pipe__vect__max_df': 0.5, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.572304 (0.007416) with: {'clf__C': 0.25, 'clf__penalty': 'l1', 'features__pipe__vect__max_df': 0.5, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.572454 (0.007505) with: {'clf__C': 0.25, 'clf__penalty': 'l1', 'features__pipe__vect__max_df': 0.5, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.572304 (0.007416) with: {'clf__C': 0.25, 'clf__penalty': 'l1', 'features__pipe__vect__max_df': 0.5, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.572454 (0.007505) with: {'clf__C': 0.25, 'clf__penalty': 'l1', 'features__pipe__vect__max_df': 0.75, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.572304 (0.007416) with: {'clf__C': 0.25, 'clf__penalty': 'l1', 'features__pipe__vect__max_df': 0.75, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.572304 (0.007416) with: {'clf__C': 0.25, 'clf__penalty': 'l1', 'features__pipe__vect__max_df': 0.75, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.572304 (0.007416) with: {'clf__C': 0.25, 'clf__penalty': 'l1', 'features__pipe__vect__max_df': 0.75, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.592493 (0.006859) with: {'clf__C': 0.25, 'clf__penalty': 'l2', 'features__pipe__vect__max_df': 0.25, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.583520 (0.012337) with: {'clf__C': 0.25, 'clf__penalty': 'l2', 'features__pipe__vect__max_df': 0.25, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.590399 (0.007739) with: {'clf__C': 0.25, 'clf__penalty': 'l2', 'features__pipe__vect__max_df': 0.25, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.588904 (0.006353) with: {'clf__C': 0.25, 'clf__penalty': 'l2', 'features__pipe__vect__max_df': 0.25, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.592493 (0.006859) with: {'clf__C': 0.25, 'clf__penalty': 'l2', 'features__pipe__vect__max_df': 0.5, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.583520 (0.012337) with: {'clf__C': 0.25, 'clf__penalty': 'l2', 'features__pipe__vect__max_df': 0.5, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.590399 (0.007739) with: {'clf__C': 0.25, 'clf__penalty': 'l2', 'features__pipe__vect__max_df': 0.5, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.588904 (0.006353) with: {'clf__C': 0.25, 'clf__penalty': 'l2', 'features__pipe__vect__max_df': 0.5, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.592493 (0.006859) with: {'clf__C': 0.25, 'clf__penalty': 'l2', 'features__pipe__vect__max_df': 0.75, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.583520 (0.012337) with: {'clf__C': 0.25, 'clf__penalty': 'l2', 'features__pipe__vect__max_df': 0.75, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.590399 (0.007739) with: {'clf__C': 0.25, 'clf__penalty': 'l2', 'features__pipe__vect__max_df': 0.75, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.588904 (0.006353) with: {'clf__C': 0.25, 'clf__penalty': 'l2', 'features__pipe__vect__max_df': 0.75, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.591446 (0.005891) with: {'clf__C': 0.5, 'clf__penalty': 'l1', 'features__pipe__vect__max_df': 0.25, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.590698 (0.004933) with: {'clf__C': 0.5, 'clf__penalty': 'l1', 'features__pipe__vect__max_df': 0.25, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.591446 (0.005891) with: {'clf__C': 0.5, 'clf__penalty': 'l1', 'features__pipe__vect__max_df': 0.25, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.590698 (0.004933) with: {'clf__C': 0.5, 'clf__penalty': 'l1', 'features__pipe__vect__max_df': 0.25, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.591446 (0.005891) with: {'clf__C': 0.5, 'clf__penalty': 'l1', 'features__pipe__vect__max_df': 0.5, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.590698 (0.004933) with: {'clf__C': 0.5, 'clf__penalty': 'l1', 'features__pipe__vect__max_df': 0.5, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.591446 (0.005891) with: {'clf__C': 0.5, 'clf__penalty': 'l1', 'features__pipe__vect__max_df': 0.5, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.590698 (0.004933) with: {'clf__C': 0.5, 'clf__penalty': 'l1', 'features__pipe__vect__max_df': 0.5, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.591297 (0.005705) with: {'clf__C': 0.5, 'clf__penalty': 'l1', 'features__pipe__vect__max_df': 0.75, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.590698 (0.004933) with: {'clf__C': 0.5, 'clf__penalty': 'l1', 'features__pipe__vect__max_df': 0.75, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.591297 (0.005705) with: {'clf__C': 0.5, 'clf__penalty': 'l1', 'features__pipe__vect__max_df': 0.75, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.590698 (0.004933) with: {'clf__C': 0.5, 'clf__penalty': 'l1', 'features__pipe__vect__max_df': 0.75, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.592044 (0.004558) with: {'clf__C': 0.5, 'clf__penalty': 'l2', 'features__pipe__vect__max_df': 0.25, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.588007 (0.010862) with: {'clf__C': 0.5, 'clf__penalty': 'l2', 'features__pipe__vect__max_df': 0.25, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.590698 (0.006632) with: {'clf__C': 0.5, 'clf__penalty': 'l2', 'features__pipe__vect__max_df': 0.25, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.589652 (0.007337) with: {'clf__C': 0.5, 'clf__penalty': 'l2', 'features__pipe__vect__max_df': 0.25, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.592044 (0.004558) with: {'clf__C': 0.5, 'clf__penalty': 'l2', 'features__pipe__vect__max_df': 0.5, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.588007 (0.010862) with: {'clf__C': 0.5, 'clf__penalty': 'l2', 'features__pipe__vect__max_df': 0.5, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.590698 (0.006632) with: {'clf__C': 0.5, 'clf__penalty': 'l2', 'features__pipe__vect__max_df': 0.5, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.589652 (0.007337) with: {'clf__C': 0.5, 'clf__penalty': 'l2', 'features__pipe__vect__max_df': 0.5, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.592044 (0.004558) with: {'clf__C': 0.5, 'clf__penalty': 'l2', 'features__pipe__vect__max_df': 0.75, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.588007 (0.010862) with: {'clf__C': 0.5, 'clf__penalty': 'l2', 'features__pipe__vect__max_df': 0.75, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.590698 (0.006632) with: {'clf__C': 0.5, 'clf__penalty': 'l2', 'features__pipe__vect__max_df': 0.75, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.589652 (0.007337) with: {'clf__C': 0.5, 'clf__penalty': 'l2', 'features__pipe__vect__max_df': 0.75, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.590997 (0.008103) with: {'clf__C': 1.0, 'clf__penalty': 'l1', 'features__pipe__vect__max_df': 0.25, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.589203 (0.007347) with: {'clf__C': 1.0, 'clf__penalty': 'l1', 'features__pipe__vect__max_df': 0.25, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.590698 (0.008599) with: {'clf__C': 1.0, 'clf__penalty': 'l1', 'features__pipe__vect__max_df': 0.25, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.589951 (0.007418) with: {'clf__C': 1.0, 'clf__penalty': 'l1', 'features__pipe__vect__max_df': 0.25, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.590997 (0.008103) with: {'clf__C': 1.0, 'clf__penalty': 'l1', 'features__pipe__vect__max_df': 0.5, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.589203 (0.007347) with: {'clf__C': 1.0, 'clf__penalty': 'l1', 'features__pipe__vect__max_df': 0.5, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.590698 (0.008599) with: {'clf__C': 1.0, 'clf__penalty': 'l1', 'features__pipe__vect__max_df': 0.5, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.589951 (0.007418) with: {'clf__C': 1.0, 'clf__penalty': 'l1', 'features__pipe__vect__max_df': 0.5, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.590997 (0.008103) with: {'clf__C': 1.0, 'clf__penalty': 'l1', 'features__pipe__vect__max_df': 0.75, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.589203 (0.007347) with: {'clf__C': 1.0, 'clf__penalty': 'l1', 'features__pipe__vect__max_df': 0.75, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.590698 (0.008599) with: {'clf__C': 1.0, 'clf__penalty': 'l1', 'features__pipe__vect__max_df': 0.75, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.589951 (0.007418) with: {'clf__C': 1.0, 'clf__penalty': 'l1', 'features__pipe__vect__max_df': 0.75, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.591446 (0.005678) with: {'clf__C': 1.0, 'clf__penalty': 'l2', 'features__pipe__vect__max_df': 0.25, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.586362 (0.009715) with: {'clf__C': 1.0, 'clf__penalty': 'l2', 'features__pipe__vect__max_df': 0.25, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.590848 (0.001558) with: {'clf__C': 1.0, 'clf__penalty': 'l2', 'features__pipe__vect__max_df': 0.25, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.589053 (0.003070) with: {'clf__C': 1.0, 'clf__penalty': 'l2', 'features__pipe__vect__max_df': 0.25, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.591446 (0.005678) with: {'clf__C': 1.0, 'clf__penalty': 'l2', 'features__pipe__vect__max_df': 0.5, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.586362 (0.009715) with: {'clf__C': 1.0, 'clf__penalty': 'l2', 'features__pipe__vect__max_df': 0.5, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.590848 (0.001558) with: {'clf__C': 1.0, 'clf__penalty': 'l2', 'features__pipe__vect__max_df': 0.5, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.589053 (0.003070) with: {'clf__C': 1.0, 'clf__penalty': 'l2', 'features__pipe__vect__max_df': 0.5, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.591446 (0.005678) with: {'clf__C': 1.0, 'clf__penalty': 'l2', 'features__pipe__vect__max_df': 0.75, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.586362 (0.009715) with: {'clf__C': 1.0, 'clf__penalty': 'l2', 'features__pipe__vect__max_df': 0.75, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.590848 (0.001558) with: {'clf__C': 1.0, 'clf__penalty': 'l2', 'features__pipe__vect__max_df': 0.75, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.589053 (0.003070) with: {'clf__C': 1.0, 'clf__penalty': 'l2', 'features__pipe__vect__max_df': 0.75, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 2)}\n"
     ]
    }
   ],
   "source": [
    "# LogisticRegression\n",
    "best_lg_countvect = grid_vect(lg, parameters_lg, X_train, X_test, parameters_text=parameters_vect, vect=countvect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidfvect = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "pipeline: ['features', 'clf']\n",
      "parameters:\n",
      "{'clf__C': (0.25, 0.5, 1.0),\n",
      " 'clf__penalty': ('l1', 'l2'),\n",
      " 'features__pipe__vect__max_df': (0.25, 0.5, 0.75),\n",
      " 'features__pipe__vect__min_df': (1, 2),\n",
      " 'features__pipe__vect__ngram_range': ((1, 1), (1, 2))}\n",
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   13.0s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:   59.3s\n",
      "[Parallel(n_jobs=-1)]: Done 360 out of 360 | elapsed:  2.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 129.417s\n",
      "\n",
      "Best CV score: 0.590\n",
      "Best parameters set:\n",
      "\tclf__C: 1.0\n",
      "\tclf__penalty: 'l1'\n",
      "\tfeatures__pipe__vect__max_df: 0.25\n",
      "\tfeatures__pipe__vect__min_df: 2\n",
      "\tfeatures__pipe__vect__ngram_range: (1, 1)\n",
      "Test score with best_estimator_: 0.593\n",
      "\n",
      "\n",
      "Classification Report Test Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.59      0.85      0.70       284\n",
      "anticipation       0.47      0.16      0.24        95\n",
      "     disgust       0.25      0.02      0.04        48\n",
      "        fear       0.62      0.59      0.60        66\n",
      "         joy       0.63      0.74      0.68       187\n",
      "        love       0.00      0.00      0.00         1\n",
      "    optimism       0.00      0.00      0.00        22\n",
      "   pessimism       0.33      0.31      0.32        16\n",
      "     sadness       0.20      0.05      0.07        22\n",
      "    surprise       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.59      0.59      0.59       744\n",
      "   macro avg       0.31      0.27      0.27       744\n",
      "weighted avg       0.53      0.59      0.53       744\n",
      "\n",
      "all results\n",
      "0.493943 (0.005306) with: {'clf__C': 0.25, 'clf__penalty': 'l1', 'features__pipe__vect__max_df': 0.25, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.466577 (0.005448) with: {'clf__C': 0.25, 'clf__penalty': 'l1', 'features__pipe__vect__max_df': 0.25, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.501720 (0.006921) with: {'clf__C': 0.25, 'clf__penalty': 'l1', 'features__pipe__vect__max_df': 0.25, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.492149 (0.008036) with: {'clf__C': 0.25, 'clf__penalty': 'l1', 'features__pipe__vect__max_df': 0.25, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.493943 (0.005306) with: {'clf__C': 0.25, 'clf__penalty': 'l1', 'features__pipe__vect__max_df': 0.5, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.466577 (0.005448) with: {'clf__C': 0.25, 'clf__penalty': 'l1', 'features__pipe__vect__max_df': 0.5, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.501720 (0.006921) with: {'clf__C': 0.25, 'clf__penalty': 'l1', 'features__pipe__vect__max_df': 0.5, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.492149 (0.008036) with: {'clf__C': 0.25, 'clf__penalty': 'l1', 'features__pipe__vect__max_df': 0.5, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.493943 (0.005306) with: {'clf__C': 0.25, 'clf__penalty': 'l1', 'features__pipe__vect__max_df': 0.75, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.466577 (0.005448) with: {'clf__C': 0.25, 'clf__penalty': 'l1', 'features__pipe__vect__max_df': 0.75, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.501720 (0.006921) with: {'clf__C': 0.25, 'clf__penalty': 'l1', 'features__pipe__vect__max_df': 0.75, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.492149 (0.008036) with: {'clf__C': 0.25, 'clf__penalty': 'l1', 'features__pipe__vect__max_df': 0.75, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.516824 (0.010986) with: {'clf__C': 0.25, 'clf__penalty': 'l2', 'features__pipe__vect__max_df': 0.25, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.493644 (0.009942) with: {'clf__C': 0.25, 'clf__penalty': 'l2', 'features__pipe__vect__max_df': 0.25, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.524600 (0.008952) with: {'clf__C': 0.25, 'clf__penalty': 'l2', 'features__pipe__vect__max_df': 0.25, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.520712 (0.010203) with: {'clf__C': 0.25, 'clf__penalty': 'l2', 'features__pipe__vect__max_df': 0.25, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.516824 (0.010986) with: {'clf__C': 0.25, 'clf__penalty': 'l2', 'features__pipe__vect__max_df': 0.5, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.493644 (0.009942) with: {'clf__C': 0.25, 'clf__penalty': 'l2', 'features__pipe__vect__max_df': 0.5, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.524600 (0.008952) with: {'clf__C': 0.25, 'clf__penalty': 'l2', 'features__pipe__vect__max_df': 0.5, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.520712 (0.010203) with: {'clf__C': 0.25, 'clf__penalty': 'l2', 'features__pipe__vect__max_df': 0.5, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.516824 (0.010986) with: {'clf__C': 0.25, 'clf__penalty': 'l2', 'features__pipe__vect__max_df': 0.75, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.493644 (0.009942) with: {'clf__C': 0.25, 'clf__penalty': 'l2', 'features__pipe__vect__max_df': 0.75, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.524600 (0.008952) with: {'clf__C': 0.25, 'clf__penalty': 'l2', 'features__pipe__vect__max_df': 0.75, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.520712 (0.010203) with: {'clf__C': 0.25, 'clf__penalty': 'l2', 'features__pipe__vect__max_df': 0.75, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.551368 (0.008352) with: {'clf__C': 0.5, 'clf__penalty': 'l1', 'features__pipe__vect__max_df': 0.25, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.528189 (0.009061) with: {'clf__C': 0.5, 'clf__penalty': 'l1', 'features__pipe__vect__max_df': 0.25, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.554210 (0.006856) with: {'clf__C': 0.5, 'clf__penalty': 'l1', 'features__pipe__vect__max_df': 0.25, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.548976 (0.006136) with: {'clf__C': 0.5, 'clf__penalty': 'l1', 'features__pipe__vect__max_df': 0.25, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.551368 (0.008352) with: {'clf__C': 0.5, 'clf__penalty': 'l1', 'features__pipe__vect__max_df': 0.5, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.528189 (0.009061) with: {'clf__C': 0.5, 'clf__penalty': 'l1', 'features__pipe__vect__max_df': 0.5, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.554210 (0.006856) with: {'clf__C': 0.5, 'clf__penalty': 'l1', 'features__pipe__vect__max_df': 0.5, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.548976 (0.006136) with: {'clf__C': 0.5, 'clf__penalty': 'l1', 'features__pipe__vect__max_df': 0.5, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.551368 (0.008352) with: {'clf__C': 0.5, 'clf__penalty': 'l1', 'features__pipe__vect__max_df': 0.75, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.528189 (0.009061) with: {'clf__C': 0.5, 'clf__penalty': 'l1', 'features__pipe__vect__max_df': 0.75, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.554210 (0.006856) with: {'clf__C': 0.5, 'clf__penalty': 'l1', 'features__pipe__vect__max_df': 0.75, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.548976 (0.006136) with: {'clf__C': 0.5, 'clf__penalty': 'l1', 'features__pipe__vect__max_df': 0.75, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.550920 (0.008258) with: {'clf__C': 0.5, 'clf__penalty': 'l2', 'features__pipe__vect__max_df': 0.25, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.534619 (0.011195) with: {'clf__C': 0.5, 'clf__penalty': 'l2', 'features__pipe__vect__max_df': 0.25, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.558098 (0.006625) with: {'clf__C': 0.5, 'clf__penalty': 'l2', 'features__pipe__vect__max_df': 0.25, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.553163 (0.006200) with: {'clf__C': 0.5, 'clf__penalty': 'l2', 'features__pipe__vect__max_df': 0.25, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.550920 (0.008258) with: {'clf__C': 0.5, 'clf__penalty': 'l2', 'features__pipe__vect__max_df': 0.5, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.534619 (0.011195) with: {'clf__C': 0.5, 'clf__penalty': 'l2', 'features__pipe__vect__max_df': 0.5, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.558098 (0.006625) with: {'clf__C': 0.5, 'clf__penalty': 'l2', 'features__pipe__vect__max_df': 0.5, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.553163 (0.006200) with: {'clf__C': 0.5, 'clf__penalty': 'l2', 'features__pipe__vect__max_df': 0.5, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.550920 (0.008258) with: {'clf__C': 0.5, 'clf__penalty': 'l2', 'features__pipe__vect__max_df': 0.75, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.534619 (0.011195) with: {'clf__C': 0.5, 'clf__penalty': 'l2', 'features__pipe__vect__max_df': 0.75, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.558098 (0.006625) with: {'clf__C': 0.5, 'clf__penalty': 'l2', 'features__pipe__vect__max_df': 0.75, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.553163 (0.006200) with: {'clf__C': 0.5, 'clf__penalty': 'l2', 'features__pipe__vect__max_df': 0.75, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.585464 (0.003688) with: {'clf__C': 1.0, 'clf__penalty': 'l1', 'features__pipe__vect__max_df': 0.25, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.575445 (0.006690) with: {'clf__C': 1.0, 'clf__penalty': 'l1', 'features__pipe__vect__max_df': 0.25, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.589652 (0.004881) with: {'clf__C': 1.0, 'clf__penalty': 'l1', 'features__pipe__vect__max_df': 0.25, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.586960 (0.006261) with: {'clf__C': 1.0, 'clf__penalty': 'l1', 'features__pipe__vect__max_df': 0.25, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.585464 (0.003688) with: {'clf__C': 1.0, 'clf__penalty': 'l1', 'features__pipe__vect__max_df': 0.5, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.575445 (0.006690) with: {'clf__C': 1.0, 'clf__penalty': 'l1', 'features__pipe__vect__max_df': 0.5, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.589652 (0.004881) with: {'clf__C': 1.0, 'clf__penalty': 'l1', 'features__pipe__vect__max_df': 0.5, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.586960 (0.006261) with: {'clf__C': 1.0, 'clf__penalty': 'l1', 'features__pipe__vect__max_df': 0.5, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.585464 (0.003688) with: {'clf__C': 1.0, 'clf__penalty': 'l1', 'features__pipe__vect__max_df': 0.75, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.575594 (0.006482) with: {'clf__C': 1.0, 'clf__penalty': 'l1', 'features__pipe__vect__max_df': 0.75, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.589652 (0.004881) with: {'clf__C': 1.0, 'clf__penalty': 'l1', 'features__pipe__vect__max_df': 0.75, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.586960 (0.006261) with: {'clf__C': 1.0, 'clf__penalty': 'l1', 'features__pipe__vect__max_df': 0.75, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.576940 (0.006946) with: {'clf__C': 1.0, 'clf__penalty': 'l2', 'features__pipe__vect__max_df': 0.25, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.568566 (0.009137) with: {'clf__C': 1.0, 'clf__penalty': 'l2', 'features__pipe__vect__max_df': 0.25, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.580529 (0.004979) with: {'clf__C': 1.0, 'clf__penalty': 'l2', 'features__pipe__vect__max_df': 0.25, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.577987 (0.006286) with: {'clf__C': 1.0, 'clf__penalty': 'l2', 'features__pipe__vect__max_df': 0.25, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.576940 (0.006946) with: {'clf__C': 1.0, 'clf__penalty': 'l2', 'features__pipe__vect__max_df': 0.5, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.568566 (0.009137) with: {'clf__C': 1.0, 'clf__penalty': 'l2', 'features__pipe__vect__max_df': 0.5, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.580529 (0.004979) with: {'clf__C': 1.0, 'clf__penalty': 'l2', 'features__pipe__vect__max_df': 0.5, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.577987 (0.006286) with: {'clf__C': 1.0, 'clf__penalty': 'l2', 'features__pipe__vect__max_df': 0.5, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.576940 (0.006946) with: {'clf__C': 1.0, 'clf__penalty': 'l2', 'features__pipe__vect__max_df': 0.75, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.568566 (0.009137) with: {'clf__C': 1.0, 'clf__penalty': 'l2', 'features__pipe__vect__max_df': 0.75, 'features__pipe__vect__min_df': 1, 'features__pipe__vect__ngram_range': (1, 2)}\n",
      "0.580529 (0.004979) with: {'clf__C': 1.0, 'clf__penalty': 'l2', 'features__pipe__vect__max_df': 0.75, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 1)}\n",
      "0.577987 (0.006286) with: {'clf__C': 1.0, 'clf__penalty': 'l2', 'features__pipe__vect__max_df': 0.75, 'features__pipe__vect__min_df': 2, 'features__pipe__vect__ngram_range': (1, 2)}\n"
     ]
    }
   ],
   "source": [
    "best_lg_tfidf = grid_vect(lg, parameters_lg, X_train, X_test, parameters_text=parameters_vect, vect=tfidfvect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#max_df: 0.25 or maximum document frequency of 25%.\n",
    "#min_df: 2 or the words need to appear in at least 2 tweets\n",
    "#ngram_range: (1, 2), both single words as bi-grams are used\n",
    "#clf__C: 1\n",
    "#clf__penalty: l2\n",
    "textcountscols = ['count_capital_words','count_emojis','count_excl_quest_marks','count_hashtags'\n",
    "                      ,'count_mentions','count_urls','count_words']\n",
    "    \n",
    "features = FeatureUnion([('textcounts', ColumnExtractor(cols=textcountscols))\n",
    "                         , ('pipe', Pipeline([('cleantext', ColumnExtractor(cols='clean_text'))\n",
    "                                              , ('vect', CountVectorizer(max_df=0.25, min_df=1, ngram_range=(1,1)))]))]\n",
    "                       , n_jobs=-1)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('features', features)\n",
    "    , ('clf', LogisticRegression(C=0.25, penalty='l2'))\n",
    "])\n",
    "\n",
    "best_model = pipeline.fit(df_model.drop('sentiment', axis=1), df_model.sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['joy', 'joy', 'joy']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_model_pos = pd.read_pickle('../data/df_model_pos.p')\n",
    "best_model.predict(df_model_pos).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['anger', 'joy', 'anger', 'anger']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_model_neg = pd.read_pickle('../data/df_model_neg.p')\n",
    "best_model.predict(df_model_neg).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
